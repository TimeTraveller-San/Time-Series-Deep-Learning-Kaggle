{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import random \n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import math\n",
    "import datetime\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import os\n",
    "import time\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "device = torch.device('cuda')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "NUM_ITEMS = 30490\n",
    "DAYS_PRED = 28\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data\"\n",
    "calendar = pd.read_csv(os.path.join(path, \"calendar.csv\"))\n",
    "selling_prices = pd.read_csv(os.path.join(path, \"sell_prices.csv\"))\n",
    "sample_submission = pd.read_csv(os.path.join(path, \"sample_submission.csv\"))\n",
    "sales = pd.read_csv(os.path.join(path, \"sales_train_evaluation.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_calendar(df):\n",
    "    df = df.drop([\"date\", \"weekday\"], axis=1)\n",
    "    df = df.assign(d = df.d.str[2:].astype(int))\n",
    "    df = df.fillna(\"missing\")\n",
    "    cols = list(set(df.columns) - {\"wm_yr_wk\", \"d\"})\n",
    "    df[cols] = OrdinalEncoder(dtype=\"int\").fit_transform(df[cols])\n",
    "    df = reduce_mem_usage(df)\n",
    "    return df\n",
    "\n",
    "calendar = prep_calendar(calendar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_selling_prices(df):\n",
    "    gr = df.groupby([\"store_id\", \"item_id\"])[\"sell_price\"]\n",
    "    df[\"sell_price_rel_diff\"] = gr.pct_change()\n",
    "    df[\"sell_price_roll_sd7\"] = gr.transform(lambda x: x.rolling(7).std())\n",
    "    df[\"sell_price_cumrel\"] = (gr.shift(0) - gr.cummin()) / (1 + gr.cummax() - gr.cummin())\n",
    "    df[\"price_unique\"] = gr.transform('nunique')\n",
    "    df = reduce_mem_usage(df)\n",
    "    return df\n",
    "\n",
    "selling_prices = prep_selling_prices(selling_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_sales(df, drop_d = None):\n",
    "    if drop_d is not None:\n",
    "        df = df.drop([\"d_\" + str(i + 1) for i in range(drop_d)], axis=1)\n",
    "    df = df.assign(id=df.id.str.replace(\"_evaluation\", \"\"))\n",
    "    df = df.reindex(columns=df.columns.tolist() + [\"d_\" + str(1913 + i + 28  + 1) for i in range(28)])\n",
    "    df = df.melt(id_vars=[\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"],\n",
    "                 var_name='d', value_name='demand')\n",
    "    df = df.assign(d=df.d.str[2:].astype(\"int16\"))\n",
    "    return df\n",
    "\n",
    "sales = reshape_sales(sales, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_sales(df):\n",
    "    df['lag_t28'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(28))\n",
    "    df['lag_t90'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(90))\n",
    "    df['lag_t180'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(180))\n",
    "    df['lag_t365'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(365))\n",
    "    df['rolling_mean_t7'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(7).mean())\n",
    "    df['rolling_mean_t30'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(30).mean())\n",
    "    df['rolling_mean_t60'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(60).mean())\n",
    "    df['rolling_mean_t90'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(90).mean())\n",
    "    df['rolling_mean_t180'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(180).mean())\n",
    "    df['rolling_std_t7'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(7).std())\n",
    "    df['rolling_std_t30'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(30).std())\n",
    "    df['rolling_std_t90'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(90).std())\n",
    "\n",
    "    # Remove rows with NAs except for submission rows. rolling_mean_t180 was selected as it produces most missings\n",
    "    df = df[(df.d >= 1941) | (pd.notna(df.rolling_mean_t180))]\n",
    "    df = reduce_mem_usage(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "sales = prep_sales(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = sales.merge(calendar, how=\"left\", on=\"d\")\n",
    "gc.collect()\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = sales.merge(selling_prices, how=\"left\", on=[\"wm_yr_wk\", \"store_id\", \"item_id\"])\n",
    "sales.drop([\"wm_yr_wk\"], axis=1, inplace=True)\n",
    "gc.collect()\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del selling_prices; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_id_cols = [\"item_id\", \"dept_id\", \"store_id\", \"cat_id\", \"state_id\"]\n",
    "cat_cols = cat_id_cols + [\"wday\", \"month\", \"year\", \"event_name_1\", \n",
    "                          \"event_type_1\", \"event_name_2\", \"event_type_2\"]\n",
    "\n",
    "for i, v in tqdm(enumerate(cat_id_cols)):\n",
    "    sales[v] = OrdinalEncoder(dtype=\"int\").fit_transform(sales[[v]])\n",
    "\n",
    "sales = reduce_mem_usage(sales)\n",
    "sales.head()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\"sell_price\", \"sell_price_rel_diff\", \"sell_price_roll_sd7\", \"sell_price_cumrel\",\n",
    "            \"lag_t28\", \"rolling_mean_t7\", \"rolling_mean_t30\", \"rolling_mean_t60\", \n",
    "            \"rolling_mean_t90\", \"rolling_mean_t180\", \"rolling_std_t7\", \"rolling_std_t30\"]\n",
    "bool_cols = [\"snap_CA\", \"snap_TX\", \"snap_WI\"]\n",
    "\n",
    "dense_cols = num_cols + bool_cols\n",
    "\n",
    "# Need to do column by column due to memory constraints\n",
    "for i, v in tqdm(enumerate(num_cols)):\n",
    "    sales[v] = sales[v].fillna(sales[v].median())\n",
    "    \n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sales[sales.d >= 1914]\n",
    "test = test.assign(id=test.id + \"_\" + np.where(test.d <= 1941, \"validation\", \"evaluation\"),\n",
    "                   F=\"F\" + (test.d - 1913 - 28 * (test.d > 1941)).astype(\"str\"))\n",
    "test.head()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_X(df):\n",
    "    X = {\"dense1\": df[dense_cols].to_numpy()}\n",
    "    for i, v in enumerate(cat_cols):\n",
    "        X[v] = df[[v]].to_numpy()\n",
    "    X['id'] = df[['id']]        \n",
    "    X['d'] = df[['d']]        \n",
    "    return X\n",
    "\n",
    "# Submission data\n",
    "X_test = make_X(test)\n",
    "\n",
    "# One month of validation data\n",
    "flag = (sales.d < 1942) & (sales.d >= 1942 - 28)\n",
    "valid = (make_X(sales[flag]),\n",
    "         sales[\"demand\"][flag])\n",
    "\n",
    "# Rest is used for training\n",
    "# flag = sales.d < 1942 - 28\n",
    "flag = sales.d < 1942 \n",
    "X_train = make_X(sales[flag])\n",
    "y_train = sales[\"demand\"][flag]\n",
    "                             \n",
    "del sales, flag\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save(x, fname):\n",
    "    with open(fname, \"wb\") as handle:\n",
    "        pickle.dump(x, handle)\n",
    "        \n",
    "save(X_train, \"X_train_final.tmp\")\n",
    "del X_train; gc.collect()\n",
    "save(y_train, \"y_train_final.tmp\")\n",
    "del y_train; gc.collect()\n",
    "save(X_test, \"X_test.tmp\")\n",
    "del X_test; gc.collect()\n",
    "save(valid, \"valid.tmp\")\n",
    "del valid; gc.collect()\n",
    "save(test, \"test.tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls *tmp -algh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def load(fname):\n",
    "    with open(fname, \"rb\") as handle:\n",
    "        return pickle.load(handle)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save(X_test, \"X_test.tmp\")\n",
    "# save(valid, \"valid.tmp\")\n",
    "# save(X_train, \"X_train.tmp\")\n",
    "# save(y_train, \"y_train.tmp\")\n",
    "# save(test, \"test.tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = load(\"X_test.tmp\")\n",
    "valid = load(\"valid.tmp\")\n",
    "X_train = load(\"X_train_final.tmp\")\n",
    "y_train = load(\"y_train_final.tmp\")\n",
    "test = load(\"test.tmp\")\n",
    "fday = X_train['d'].values.flatten().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22379655</th>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22379656</th>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22379657</th>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22379658</th>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22379659</th>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             d\n",
       "22379655  1941\n",
       "22379656  1941\n",
       "22379657  1941\n",
       "22379658  1941\n",
       "22379659  1941"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['d'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22379655</th>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22379656</th>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22379657</th>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22379658</th>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22379659</th>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             d\n",
       "22379655  1941\n",
       "22379656  1941\n",
       "22379657  1941\n",
       "22379658  1941\n",
       "22379659  1941"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid[0]['d'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1931</th>\n",
       "      <th>1932</th>\n",
       "      <th>1933</th>\n",
       "      <th>1934</th>\n",
       "      <th>1935</th>\n",
       "      <th>1936</th>\n",
       "      <th>1937</th>\n",
       "      <th>1938</th>\n",
       "      <th>1939</th>\n",
       "      <th>1940</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_001_CA_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_002_CA_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_003_CA_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_004_CA_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_005_CA_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1941 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0     1     2     3     4     5     6     7     8     \\\n",
       "id                                                                         \n",
       "HOBBIES_1_001_CA_1     0     0     0     0     0     0     0     0     0   \n",
       "HOBBIES_1_002_CA_1     0     0     0     0     0     0     0     0     0   \n",
       "HOBBIES_1_003_CA_1     0     0     0     0     0     0     0     0     0   \n",
       "HOBBIES_1_004_CA_1     0     0     0     0     0     0     0     0     0   \n",
       "HOBBIES_1_005_CA_1     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "                    9     ...  1931  1932  1933  1934  1935  1936  1937  1938  \\\n",
       "id                        ...                                                   \n",
       "HOBBIES_1_001_CA_1     0  ...     2     4     0     0     0     0     3     3   \n",
       "HOBBIES_1_002_CA_1     0  ...     0     1     2     1     1     0     0     0   \n",
       "HOBBIES_1_003_CA_1     0  ...     1     0     2     0     0     0     2     3   \n",
       "HOBBIES_1_004_CA_1     0  ...     1     1     0     4     0     1     3     0   \n",
       "HOBBIES_1_005_CA_1     0  ...     0     0     0     2     1     0     0     2   \n",
       "\n",
       "                    1939  1940  \n",
       "id                              \n",
       "HOBBIES_1_001_CA_1     0     1  \n",
       "HOBBIES_1_002_CA_1     0     0  \n",
       "HOBBIES_1_003_CA_1     0     1  \n",
       "HOBBIES_1_004_CA_1     2     6  \n",
       "HOBBIES_1_005_CA_1     1     0  \n",
       "\n",
       "[5 rows x 1941 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../data\"\n",
    "sales_df = pd.read_csv(os.path.join(path, \"sales_train_evaluation.csv\"))\n",
    "sales_df.id = sales_df.id.apply(lambda x : \"_\".join(x.split(\"_\")[:-1]))\n",
    "sales_df.index = sales_df.id\n",
    "sales_df = sales_df.drop([\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"], axis=1)\n",
    "cols = [i for i in range(1941)]\n",
    "sales_df.columns = cols\n",
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_id_cols = [\"item_id\", \"dept_id\", \"store_id\", \"cat_id\", \"state_id\"]\n",
    "cat_cols = cat_id_cols + [\"wday\", \"month\", \"year\", \"event_name_1\", \n",
    "                          \"event_type_1\", \"event_name_2\", \"event_type_2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     6,
     17,
     32
    ]
   },
   "outputs": [],
   "source": [
    "class M5Loader:\n",
    "    def __init__(self, X, y, sales_df, shuffle=True, \n",
    "                 batch_size=10000, seq_len=56, \n",
    "                 cat_cols=[], ret_garbage=False,\n",
    "                 reduce=None):\n",
    "        \n",
    "        if reduce is not None:\n",
    "            n = X[\"dense1\"].shape[0]\n",
    "            k = int((1-reduce)*n)\n",
    "            reduced_idxs = np.random.choice([i for i in range(n)], k, replace=False)\n",
    "            \n",
    "        self.X_cont = X[\"dense1\"]\n",
    "        self.X_cat = np.concatenate([X[k] for k in cat_cols], axis=1)\n",
    "        self.ids = X[\"id\"].values.flatten()\n",
    "        self.ds = X[\"d\"].values.flatten()\n",
    "        self.y = y\n",
    "        \n",
    "        if reduce is not None:\n",
    "            self.X_cont = self.X_cont[[reduced_idxs]]\n",
    "            self.X_cat = self.X_cat[[reduced_idxs]]\n",
    "            self.ids = self.ids[[reduced_idxs]]\n",
    "            self.ds = self.ds[[reduced_idxs]]\n",
    "            self.y = self.y[[reduced_idxs]]\n",
    "\n",
    "        self.sales_df = sales_df\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        self.seq_len = seq_len\n",
    "        self.n_conts = self.X_cont.shape[1]\n",
    "        self.len = self.X_cont.shape[0]\n",
    "        n_batches, remainder = divmod(self.len, self.batch_size)\n",
    "        \n",
    "        if remainder > 0:\n",
    "            n_batches += 1\n",
    "        self.n_batches = n_batches\n",
    "        self.remainder = remainder #for debugging\n",
    "        \n",
    "        self.idxes = np.array([i for i in range(self.len)])\n",
    "        self.ret_garbage = ret_garbage #For last 28/56 days of test set which cant be predicted right now\n",
    "        self.always_garbage = False\n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.i = 0\n",
    "        if self.shuffle:\n",
    "            ridxes = self.idxes\n",
    "            np.random.shuffle(ridxes)\n",
    "            self.X_cat = self.X_cat[[ridxes]]\n",
    "            self.X_cont = self.X_cont[[ridxes]]\n",
    "            self.ids = self.ids[[ridxes]]\n",
    "            self.ds = self.ds[[ridxes]]\n",
    "            if self.y is not None:\n",
    "                self.y = self.y[[ridxes]]\n",
    "                \n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.i  >= self.len:\n",
    "            raise StopIteration\n",
    "        \n",
    "        if self.always_garbage:\n",
    "            self.i += self.batch_size\n",
    "            return None, None, None, None\n",
    "            \n",
    "        if self.y is not None:\n",
    "            y = torch.FloatTensor(self.y[self.i:self.i+self.batch_size].astype(np.float32))\n",
    "        else:\n",
    "            y = None\n",
    "        \n",
    "         \n",
    "        ids = self.ids[self.i:self.i+self.batch_size]      \n",
    "        ds = self.ds[self.i:self.i+self.batch_size]\n",
    "        cur_batch_size = ids.shape[0]\n",
    "        hist = np.zeros((cur_batch_size, self.seq_len))\n",
    "        horizon = 28 \n",
    "        \n",
    "        if self.ret_garbage:\n",
    "            try:\n",
    "                for past in range(self.seq_len):\n",
    "                    hist[:, past] = self.sales_df.lookup(ids, ds-horizon-self.seq_len+past) #TODO: pandas lookup is slow, maybe hash ids and do a npy lookup\n",
    "            except:\n",
    "                print(\"NOOOOOOO This should not happen\")\n",
    "                self.always_garbage = True\n",
    "                return None, None, None, None\n",
    "        else:\n",
    "              for past in range(self.seq_len):\n",
    "                    hist[:, past] = self.sales_df.lookup(ids, ds-horizon-self.seq_len+past) #TODO: pandas lookup is slow, maybe hash ids and do a npy lookup\n",
    "                    \n",
    "        xcont = torch.FloatTensor(self.X_cont[self.i:self.i+self.batch_size])\n",
    "        xcat = torch.LongTensor(self.X_cat[self.i:self.i+self.batch_size])\n",
    "        xhist = torch.FloatTensor(hist)\n",
    "        \n",
    "        batch = (xcont, xcat, xhist, y)\n",
    "        self.i += self.batch_size\n",
    "        return batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_batches           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader len: 22379660\n",
      "Val loader len: 853720\n",
      "Test loader len: 1707440\n"
     ]
    }
   ],
   "source": [
    "# bs = 10000\n",
    "bs = 2**11\n",
    "# bs = 2**7\n",
    "shuffle = True\n",
    "seq_len = int(28*4)\n",
    "reduce = None\n",
    "\n",
    "train_loader = M5Loader(X_train, y_train.values, \n",
    "                                                sales_df, cat_cols=cat_cols, \n",
    "                                                batch_size=bs, seq_len=seq_len,\n",
    "                                                shuffle=shuffle, reduce=reduce)\n",
    "\n",
    "val_loader = M5Loader(valid[0], valid[1].values,\n",
    "                                                sales_df, cat_cols=cat_cols, \n",
    "                                                batch_size=bs, seq_len=seq_len,\n",
    "                                                shuffle=False)\n",
    "\n",
    "X_test['id'].id = X_test['id'].id.apply(lambda x : \"_\".join(x.split(\"_\")[:-1]))\n",
    "test_loader = M5Loader(X_test, y=None,\n",
    "                                                sales_df=sales_df, cat_cols=cat_cols, \n",
    "                                                batch_size=NUM_ITEMS, seq_len=seq_len,\n",
    "                                                shuffle=False, ret_garbage=False)\n",
    "\n",
    "print(f\"Train loader len: {train_loader.len}\")\n",
    "print(f\"Val loader len: {val_loader.len}\")\n",
    "print(f\"Test loader len: {test_loader.len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, col in enumerate(cat_cols):\n",
    "#     print(col, \"\\t\", np.unique(train_loader.X_cat[:, i]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3049, 5), (7, 1), (10, 1), (3, 1), (3, 1), (7, 1), (12, 1), (6, 1), (31, 1), (5, 1), (5, 1), (5, 1)]\n"
     ]
    }
   ],
   "source": [
    "uniques = [3049, 7, 10, 3, 3, 7, 12, 6, 31, 5, 5, 5]\n",
    "# dims = [3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "dims = [5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "emb_dims = [(x, y) for x, y in zip(uniques, dims)]\n",
    "print(emb_dims)\n",
    "n_cont = train_loader.n_conts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "426b07f6171a4fd29acbdb5f8fe19bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.34 s, sys: 172 ms, total: 8.51 s\n",
      "Wall time: 8.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i, (X_cont, X_cat, xhist, y) in enumerate(tqdm(train_loader)):\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss functions and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     2,
     12,
     22,
     27,
     40,
     56,
     67,
     70,
     105
    ]
   },
   "outputs": [],
   "source": [
    "calc_wrmsse = True\n",
    "\n",
    "class RMSE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_pred = y_pred.squeeze()\n",
    "        y_true = torch.FloatTensor(y).to(device)\n",
    "        return torch.sqrt(self.mse(y_pred, y_true))    \n",
    "    \n",
    "class MSE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_pred = y_pred.squeeze()\n",
    "        y_true = torch.FloatTensor(y).to(device)\n",
    "        return self.mse(y_pred, y_true)  \n",
    "\n",
    "def rmse_metric(y_pred, y_true):\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    return np.sqrt(np.mean((y_pred-y_true)**2))       \n",
    "\n",
    "class Assymetric_RMSE(nn.Module):\n",
    "    def __init__(self, penalty=1.5):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.penalty = penalty\n",
    "        \n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_pred = y_pred.squeeze()\n",
    "        y_true = torch.FloatTensor(y).to(device)\n",
    "#         error = torch.where(y_true==0, (y_true-y_pred)**2, self.penalty*(y_true-y_pred)**2)\n",
    "        error = torch.where(y_true==0, self.penalty*(y_true-y_pred)**2, (y_true-y_pred)**2)\n",
    "        return torch.sqrt(torch.mean(error))\n",
    "    \n",
    "class Tweedie(nn.Module):\n",
    "    def __init__(self, rho=1.5):\n",
    "        super().__init__()\n",
    "        self.rho = rho\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        eps = 1e-10\n",
    "        y_pred = y_pred.squeeze() + eps\n",
    "        y_true = torch.FloatTensor(y).to(device) + eps\n",
    "        rho = self.rho\n",
    "        a = y_true * torch.pow(y_pred, (1-rho))  / (1-rho) \n",
    "        b = torch.pow(y_pred, (2-rho))  / (2-rho) \n",
    "        tweedie = -a + b\n",
    "        loss = torch.mean(tweedie)\n",
    "        return loss       \n",
    "    \n",
    "if calc_wrmsse:\n",
    "    roll_mat_df = pd.read_pickle('../data/roll_mat_df.pkl')\n",
    "    roll_index = roll_mat_df.index\n",
    "    roll_mat_csr = csr_matrix(roll_mat_df.values)\n",
    "    del roll_mat_df; gc.collect()\n",
    "\n",
    "    sw_df = pd.read_pickle('../data/sw_df.pkl')\n",
    "    s = sw_df.s.values\n",
    "    w = sw_df.w.values\n",
    "    sw = sw_df.sw.values   \n",
    "    \n",
    "def rollup(v, roll_mat_csr):\n",
    "    return roll_mat_csr*v #(v.T*roll_mat_csr.T).T\n",
    "\n",
    "def wrmsse_metric(preds, y_true, score_only=True, npy=True, roll_mat_csr=None, sw=None, verbose=False):\n",
    "    preds = np.array(preds).reshape(NUM_ITEMS, -1)\n",
    "    y_true = np.array(y_true).reshape(NUM_ITEMS, -1)\n",
    "    \n",
    "    if verbose:\n",
    "        print(preds.shape)\n",
    "        print(y_true.shape)\n",
    "    \n",
    "    if roll_mat_csr is None:\n",
    "        roll_mat_df = pd.read_pickle('../data/roll_mat_df.pkl')\n",
    "        roll_index = roll_mat_df.index\n",
    "        roll_mat_csr = csr_matrix(roll_mat_df.values)\n",
    "        del roll_mat_df; gc.collect()\n",
    "\n",
    "    if sw is None:\n",
    "        sw_df = pd.read_pickle('../data/sw_df.pkl')\n",
    "        s = sw_df.s.values\n",
    "        w = sw_df.w.values\n",
    "        sw = sw_df.sw.values\n",
    "\n",
    "    if not npy:\n",
    "        preds = preds.values\n",
    "        y_true = y_true.values\n",
    "    \n",
    "    if score_only:\n",
    "        return np.sum(\n",
    "                np.sqrt(\n",
    "                    np.mean(\n",
    "                        np.square(rollup(preds-y_true, roll_mat_csr))\n",
    "                            ,axis=1)) * sw)/12 \n",
    "    else: \n",
    "        score_matrix = (np.square(rollup(preds-y_true, roll_mat_csr)) * np.square(w)[:, None])/ s[:, None]\n",
    "        score = np.sum(np.sqrt(np.mean(score_matrix,axis=1)))/12 \n",
    "        return score, score_matrix\n",
    "\n",
    "def rmse_metric(y_pred, y_true):\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    return np.sqrt(np.mean((y_pred-y_true)**2))                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0,
     5,
     18
    ]
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "        \n",
    "class LinearBlock(nn.Module):\n",
    "    def __init__(self, in_d, out_d, p=0):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "                            nn.Linear(in_d, out_d),\n",
    "                            nn.ReLU(),\n",
    "#                             nn.LeakyReLU(),\n",
    "#                             nn.Tanh(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "    \n",
    "class ConvModule(nn.Module):\n",
    "    def __init__(self, seq_len=56):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.global_conv = nn.Conv1d(1, 1, kernel_size=(seq_len))\n",
    "        self.week_conv = nn.Conv1d(1, 1, kernel_size=(7))\n",
    "        self.biweek_conv = nn.Conv1d(1, 1, kernel_size=(14))\n",
    "        self.month_conv = nn.Conv1d(1, 1, kernel_size=(24)) #yea, yea, a month is not 28 days. But quadweek is a big word. \n",
    "        self.bimonth_conv = nn.Conv1d(1, 1, kernel_size=(48)) \n",
    "\n",
    "        self.last_week_conv = nn.Conv1d(1, 1, kernel_size=(7))\n",
    "        self.last_biweek_conv = nn.Conv1d(1, 1, kernel_size=(14))\n",
    "        \n",
    "        self.drop_large = nn.Dropout(0.35)\n",
    "        self.drop_small = nn.Dropout(0.15)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x[:, None, :] #insert 1 channel (bs, channel, timesteps)\n",
    "        bs = x.shape[0]\n",
    "        \n",
    "        out1 = self.global_conv(x).view(bs, -1)\n",
    "        out1 = self.drop_large(out1)\n",
    "        \n",
    "        out2 = self.week_conv(x).view(bs, -1)\n",
    "        out2 = self.drop_large(out2)\n",
    "        \n",
    "        out3 = self.biweek_conv(x).view(bs, -1)\n",
    "        out3 = self.drop_large(out3)\n",
    "        \n",
    "        out4 = self.month_conv(x).view(bs, -1)\n",
    "        out4 = self.drop_large(out4)\n",
    "        \n",
    "        out6 = self.last_week_conv(x[:, :, -7:]).view(bs, -1)\n",
    "        out6 = self.drop_small(out6)     \n",
    "        \n",
    "        out7 = self.last_biweek_conv(x[:, :, -14:]).view(bs, -1)\n",
    "        out7 = self.drop_small(out7)             \n",
    "        \n",
    "        out = torch.cat([out1, out2, out3, out4, out6, out7], axis=1)\n",
    "        return out\n",
    "\n",
    "class M5Net(nn.Module):\n",
    "    def __init__(self, emb_dims, n_cont, seq_len=56, device=device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.convs = ConvModule(seq_len)\n",
    "\n",
    "        # Embedding layers\n",
    "        self.emb_layers = nn.ModuleList([nn.Embedding(x, y) for x, y in emb_dims])\n",
    "        n_embs = sum([y for x, y in emb_dims])\n",
    "        \n",
    "        self.n_embs = n_embs\n",
    "        self.n_cont = n_cont\n",
    "        \n",
    "        inp_dim = 384 #got this via an error, todo: write a lazy loader\n",
    "#         hidden_dim = 300\n",
    "        hidden_dim = inp_dim//2\n",
    "        \n",
    "        self.fn = nn.Sequential(\n",
    "                 LinearBlock(inp_dim, hidden_dim),\n",
    "                 LinearBlock(hidden_dim, hidden_dim//2),\n",
    "                 LinearBlock(hidden_dim//2, hidden_dim//4),\n",
    "        )          \n",
    "        \n",
    "        self.out = nn.Linear(hidden_dim//4, 1)\n",
    "\n",
    "        self.fn.apply(init_weights)\n",
    "        self.out.apply(init_weights)\n",
    "        \n",
    "\n",
    "    def encode_and_combine_data(self, cont_data, cat_data):\n",
    "        xcat = [el(cat_data[:, k]) for k, el in enumerate(self.emb_layers)]\n",
    "        xcat = torch.cat(xcat, 1)\n",
    "        x = torch.cat([xcat, cont_data], axis=1)\n",
    "        return x   \n",
    "    \n",
    "    def forward(self, cont_data, cat_data, hist_data):\n",
    "        cont_data = cont_data.to(self.device)\n",
    "        cat_data = cat_data.to(self.device)\n",
    "        hist_data = hist_data.to(self.device)\n",
    "        \n",
    "        x1 = self.encode_and_combine_data(cont_data, cat_data)\n",
    "        x2 = self.convs(hist_data)\n",
    "        x = torch.cat([x1, x2], axis=1)\n",
    "        x = self.fn(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = M5Net(emb_dims, n_cont).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M5Net(\n",
       "  (convs): ConvModule(\n",
       "    (global_conv): Conv1d(1, 1, kernel_size=(56,), stride=(1,))\n",
       "    (week_conv): Conv1d(1, 1, kernel_size=(7,), stride=(1,))\n",
       "    (biweek_conv): Conv1d(1, 1, kernel_size=(14,), stride=(1,))\n",
       "    (month_conv): Conv1d(1, 1, kernel_size=(24,), stride=(1,))\n",
       "    (bimonth_conv): Conv1d(1, 1, kernel_size=(48,), stride=(1,))\n",
       "    (last_week_conv): Conv1d(1, 1, kernel_size=(7,), stride=(1,))\n",
       "    (last_biweek_conv): Conv1d(1, 1, kernel_size=(14,), stride=(1,))\n",
       "    (drop_large): Dropout(p=0.35, inplace=False)\n",
       "    (drop_small): Dropout(p=0.15, inplace=False)\n",
       "  )\n",
       "  (emb_layers): ModuleList(\n",
       "    (0): Embedding(3049, 5)\n",
       "    (1): Embedding(7, 1)\n",
       "    (2): Embedding(10, 1)\n",
       "    (3): Embedding(3, 1)\n",
       "    (4): Embedding(3, 1)\n",
       "    (5): Embedding(7, 1)\n",
       "    (6): Embedding(12, 1)\n",
       "    (7): Embedding(6, 1)\n",
       "    (8): Embedding(31, 1)\n",
       "    (9): Embedding(5, 1)\n",
       "    (10): Embedding(5, 1)\n",
       "    (11): Embedding(5, 1)\n",
       "  )\n",
       "  (fn): Sequential(\n",
       "    (0): LinearBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Linear(in_features=384, out_features=192, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (1): LinearBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Linear(in_features=192, out_features=96, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (2): LinearBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Linear(in_features=96, out_features=48, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Linear(in_features=48, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.2008, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "CPU times: user 5.86 s, sys: 160 ms, total: 6.02 s\n",
      "Wall time: 6.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "criterion = RMSE()\n",
    "for i, (X_cont, X_cat, X_hist, y) in enumerate(train_loader): #most of the time is spent in fresh randomzing inputs at every __iter__ call so dw\n",
    "    out = model(X_cont, X_cat, X_hist)\n",
    "    loss = criterion(out, y)   \n",
    "    loss.backward()\n",
    "    print(loss)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using adam optimizer.\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "optim = \"adam\"\n",
    "lr_adam = 3e-4\n",
    "lr_sgd = 1e-3\n",
    "criterion = RMSE()\n",
    "torch.manual_seed(777)\n",
    "model = M5Net(emb_dims, n_cont).to(device)\n",
    "model_name = \"final_submit\"\n",
    "\n",
    "if optim == \"adam\":\n",
    "    print(\"Using adam optimizer.\")\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr_adam)\n",
    "else:\n",
    "    print(\"Not using adam optimizer.\")\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr_sgd, momentum=0.9)\n",
    "    \n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "#                     optimizer, [20, 25, 30], gamma=0.5, \n",
    "#                     last_epoch=-1)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "                    optimizer, 5, T_mult=2, \n",
    "                    eta_min=3e-5, last_epoch=-1)\n",
    "\n",
    "def save(m, fname, dirname='/home/timetraveller/Work/M5Models-Final/'):\n",
    "    with open(os.path.join(dirname, fname), 'wb') as handle:\n",
    "        pickle.dump(m, handle)\n",
    "    print(\"saved model\")    \n",
    "        \n",
    "def zero_percentage(q):\n",
    "    l = len(q)\n",
    "    q = np.array(q)\n",
    "    return sum(q<1)/l        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54943d56e33a4cbdbda7a865c755bcc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "705649b9c7204609b4cd1a8590c8bda9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 0 | Loss: 2.3136 | RMSE: 2.3558\n",
      "[Valid] Epoch: 0 | Loss: 2.0829 | RMSE: 2.1702 | WRMSSE: 0.4707 | zc: 0.642/0.544\n",
      "[Test] Epoch: 0 | zc: 0.632/???\n",
      "saved model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5861762bc145a6bc62cca988c17760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 1 | Loss: 2.2637 | RMSE: 2.3045\n",
      "[Valid] Epoch: 1 | Loss: 2.0667 | RMSE: 2.1532 | WRMSSE: 0.6456 | zc: 0.678/0.544\n",
      "[Test] Epoch: 1 | zc: 0.669/???\n",
      "saved model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e3bfc620fe47c5b04334779564d940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 2 | Loss: 2.2393 | RMSE: 2.2795\n",
      "[Valid] Epoch: 2 | Loss: 2.0596 | RMSE: 2.1430 | WRMSSE: 0.6824 | zc: 0.679/0.544\n",
      "[Test] Epoch: 2 | zc: 0.667/???\n",
      "saved model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b80b240c35ff4e42a65ecda90cd2b1a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 3 | Loss: 2.2222 | RMSE: 2.2619\n",
      "[Valid] Epoch: 3 | Loss: 2.0507 | RMSE: 2.1312 | WRMSSE: 0.4367 | zc: 0.651/0.544\n",
      "[Test] Epoch: 3 | zc: 0.636/???\n",
      "saved model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f785f2c626400fac79c1664942eae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 4 | Loss: 2.2121 | RMSE: 2.2509\n",
      "[Valid] Epoch: 4 | Loss: 2.0451 | RMSE: 2.1258 | WRMSSE: 0.4633 | zc: 0.651/0.544\n",
      "[Test] Epoch: 4 | zc: 0.635/???\n",
      "saved model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b908571573b14f54a242aded53ae7174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 5 | Loss: 2.2205 | RMSE: 2.2597\n",
      "[Valid] Epoch: 5 | Loss: 2.0654 | RMSE: 2.1508 | WRMSSE: 0.5321 | zc: 0.652/0.544\n",
      "[Test] Epoch: 5 | zc: 0.638/???\n",
      "saved model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d4f3cbf989456e983171d2d70f4669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 6 | Loss: 2.2035 | RMSE: 2.2424\n",
      "[Valid] Epoch: 6 | Loss: 2.0352 | RMSE: 2.1127 | WRMSSE: 0.4917 | zc: 0.620/0.544\n",
      "[Test] Epoch: 6 | zc: 0.595/???\n",
      "saved model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe1d65db90f04e398164a306a4d331ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 7 | Loss: 2.1864 | RMSE: 2.2246\n",
      "[Valid] Epoch: 7 | Loss: 2.0283 | RMSE: 2.1043 | WRMSSE: 0.5085 | zc: 0.656/0.544\n",
      "[Test] Epoch: 7 | zc: 0.636/???\n",
      "saved model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6745fea0b9bc4365ac5e8dc758503b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 8 | Loss: 2.1696 | RMSE: 2.2068\n",
      "[Valid] Epoch: 8 | Loss: 2.0236 | RMSE: 2.0981 | WRMSSE: 0.4229 | zc: 0.638/0.544\n",
      "[Test] Epoch: 8 | zc: 0.612/???\n",
      "saved model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d671d33e7dc43be9b6401943a576c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 9 | Loss: 2.1533 | RMSE: 2.1892\n",
      "[Valid] Epoch: 9 | Loss: 2.0162 | RMSE: 2.0889 | WRMSSE: 0.5036 | zc: 0.649/0.544\n",
      "[Test] Epoch: 9 | zc: 0.624/???\n",
      "saved model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5688e0949614495a865d5beb7d5e50d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 10 | Loss: 2.1392 | RMSE: 2.1745\n",
      "[Valid] Epoch: 10 | Loss: 2.0110 | RMSE: 2.0814 | WRMSSE: 0.4492 | zc: 0.645/0.544\n",
      "[Test] Epoch: 10 | zc: 0.621/???\n",
      "saved model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4fd52a741e347d99c308afea5992806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 11 | Loss: 2.1287 | RMSE: 2.1631\n",
      "[Valid] Epoch: 11 | Loss: 2.0064 | RMSE: 2.0759 | WRMSSE: 0.4156 | zc: 0.641/0.544\n",
      "[Test] Epoch: 11 | zc: 0.617/???\n",
      "saved model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ff2f54008148ee8b05af67c99bd775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 12 | Loss: 2.1183 | RMSE: 2.1514\n",
      "[Valid] Epoch: 12 | Loss: 2.0034 | RMSE: 2.0716 | WRMSSE: 0.4265 | zc: 0.646/0.544\n",
      "[Test] Epoch: 12 | zc: 0.619/???\n",
      "saved model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efff0daac2054aa1a645fb012bc74ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 13 | Loss: 2.1117 | RMSE: 2.1441\n",
      "[Valid] Epoch: 13 | Loss: 1.9996 | RMSE: 2.0667 | WRMSSE: 0.4579 | zc: 0.651/0.544\n",
      "[Test] Epoch: 13 | zc: 0.626/???\n",
      "saved model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28cf1196b3a449b68ed9f800627782b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 14 | Loss: 2.1086 | RMSE: 2.1405\n",
      "[Valid] Epoch: 14 | Loss: 1.9967 | RMSE: 2.0633 | WRMSSE: 0.4205 | zc: 0.643/0.544\n",
      "[Test] Epoch: 14 | zc: 0.619/???\n",
      "saved model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f7c703b4ee1460caefd9745f7d493c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 15 | Loss: 2.1332 | RMSE: 2.1678\n",
      "[Valid] Epoch: 15 | Loss: 2.0077 | RMSE: 2.0762 | WRMSSE: 0.4250 | zc: 0.647/0.544\n",
      "[Test] Epoch: 15 | zc: 0.619/???\n",
      "saved model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d691b6457e8a4cb0ab39692ebb1b715f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 16 | Loss: 2.1272 | RMSE: 2.1623\n",
      "[Valid] Epoch: 16 | Loss: 2.0035 | RMSE: 2.0727 | WRMSSE: 0.5330 | zc: 0.665/0.544\n",
      "[Test] Epoch: 16 | zc: 0.642/???\n",
      "saved model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7254bd0adf42cba31410cee3cc8959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 17 | Loss: 2.1190 | RMSE: 2.1526\n",
      "[Valid] Epoch: 17 | Loss: 2.0073 | RMSE: 2.0774 | WRMSSE: 0.4189 | zc: 0.635/0.544\n",
      "[Test] Epoch: 17 | zc: 0.600/???\n",
      "saved model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc290234a7e04614bf168ea375e959ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 18 | Loss: 2.1098 | RMSE: 2.1421\n",
      "[Valid] Epoch: 18 | Loss: 1.9970 | RMSE: 2.0644 | WRMSSE: 0.4106 | zc: 0.643/0.544\n",
      "[Test] Epoch: 18 | zc: 0.610/???\n",
      "saved model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e30eb47fc5804250a33f7a18ab185ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 19 | Loss: 2.1022 | RMSE: 2.1346\n",
      "[Valid] Epoch: 19 | Loss: 1.9938 | RMSE: 2.0608 | WRMSSE: 0.5703 | zc: 0.669/0.544\n",
      "[Test] Epoch: 19 | zc: 0.638/???\n",
      "saved model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5688dc7024943d2be52aa5854277bf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 20 | Loss: 2.0928 | RMSE: 2.1245\n",
      "[Valid] Epoch: 20 | Loss: 1.9901 | RMSE: 2.0553 | WRMSSE: 0.4226 | zc: 0.653/0.544\n",
      "[Test] Epoch: 20 | zc: 0.614/???\n",
      "saved model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba481a37f514fd5a559265b545eae40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 21 | Loss: 2.0853 | RMSE: 2.1157\n",
      "[Valid] Epoch: 21 | Loss: 1.9828 | RMSE: 2.0465 | WRMSSE: 0.4691 | zc: 0.661/0.544\n",
      "[Test] Epoch: 21 | zc: 0.631/???\n",
      "saved model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64979b5abe8340249265c0a84e625da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 22 | Loss: 2.0801 | RMSE: 2.1099\n",
      "[Valid] Epoch: 22 | Loss: 1.9787 | RMSE: 2.0410 | WRMSSE: 0.4160 | zc: 0.649/0.544\n",
      "[Test] Epoch: 22 | zc: 0.609/???\n",
      "saved model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5340b6f07a564166a20d4b9aa5967451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 23 | Loss: 2.0708 | RMSE: 2.0995\n",
      "[Valid] Epoch: 23 | Loss: 1.9747 | RMSE: 2.0365 | WRMSSE: 0.4197 | zc: 0.651/0.544\n",
      "[Test] Epoch: 23 | zc: 0.619/???\n",
      "saved model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b59eaa3bec44e168ce095e2bf5b1887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss, val_loss = 0, 0\n",
    "   \n",
    "    #Training phase\n",
    "    model.train()\n",
    "    ypreds = [] \n",
    "    ytrue = []\n",
    "    bar = tqdm(train_loader)\n",
    "    \n",
    "    for i, (X_cont, X_cat, X_hist, y) in enumerate(bar):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(X_cont, X_cat, X_hist)\n",
    "        loss = criterion(out, y)   \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step(epoch + i/len(train_loader))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            train_loss += loss.item()/len(train_loader)\n",
    "            ypreds += list(out.detach().cpu().numpy().flatten())\n",
    "            ytrue += list(y.cpu().numpy())\n",
    "            bar.set_description(f\"{loss.item():.3f}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        rrmse = rmse_metric(ypreds, ytrue)\n",
    "        print(f\"[Train] Epoch: {epoch} | Loss: {train_loss:.4f} | RMSE: {rrmse:.4f}\")\n",
    "    \n",
    "    #Validation phase      \n",
    "    with torch.no_grad():\n",
    "            model.eval()\n",
    "            ytrue = []\n",
    "            ypreds = []\n",
    "            \n",
    "            for i, (X_cont, X_cat, X_hist, y) in enumerate(val_loader):\n",
    "                out = model(X_cont, X_cat, X_hist)\n",
    "                val_loss += criterion(out, y).item()/len(val_loader)\n",
    "                ypreds += list(out.detach().cpu().numpy().flatten())\n",
    "                ytrue += list(y.cpu().numpy())\n",
    "                \n",
    "            rrmse = rmse_metric(ypreds, ytrue)    \n",
    "            wrmsse = wrmsse_metric(ypreds, ytrue, roll_mat_csr=roll_mat_csr, sw=sw)\n",
    "            zc = zero_percentage(ypreds)\n",
    "            \n",
    "            print(f\"[Valid] Epoch: {epoch} | Loss: {val_loss:.4f} | RMSE: {rrmse:.4f} | WRMSSE: {wrmsse:.4f} | zc: {zc:.3f}/0.544\")\n",
    "            \n",
    "            #Test's zc\n",
    "            for i, (X_cont, X_cat, X_hist, y) in enumerate(test_loader):\n",
    "                out = model(X_cont, X_cat, X_hist)\n",
    "                ypreds += list(out.detach().cpu().numpy().flatten())\n",
    "            zc = zero_percentage(ypreds[-NUM_ITEMS*28:]) #Last 28 days only\n",
    "            print(f\"[Test] Epoch: {epoch} | zc: {zc:.3f}/???\")            \n",
    "      \n",
    "    train_losses.append(train_loss)    \n",
    "    val_losses.append(val_loss)   \n",
    "    save_data = {\n",
    "            'model' : model,\n",
    "            'optimizer' : optimizer,\n",
    "            'scheduler' : scheduler,\n",
    "            'epoch' : epoch,\n",
    "            'train_losses' : train_losses,\n",
    "            'val_losses' : val_losses,\n",
    "        }\n",
    "    save(save_data, f\"{model_name}_{epoch}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['dense1'].shape[0]/NUM_ITEMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['id'].id = X_test['id'].id.apply(lambda x : \"_\".join(x.split(\"_\")[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = M5Loader(X_test, y=None,\n",
    "                                                sales_df=sales_df, cat_cols=cat_cols, \n",
    "                                                batch_size=NUM_ITEMS, seq_len=seq_len,\n",
    "                                                shuffle=False, ret_garbage=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d4d1220852435087bc53ab074fc12b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=56), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOOOOOOO This should not happen\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'out_npy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-5f57b822d47a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_cont\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mX_cont\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                 \u001b[0mout_npy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_npy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cont\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_hist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'out_npy' is not defined"
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "with torch.no_grad():\n",
    "#         model.eval()\n",
    "        for i, (X_cont, X_cat, X_hist, y) in enumerate(tqdm(test_loader)):\n",
    "            if X_cont is None:\n",
    "                out_npy = np.zeros_like(out_npy)\n",
    "            else:    \n",
    "                out = model(X_cont, X_cat, X_hist)\n",
    "                out_npy = out.cpu().numpy().flatten()\n",
    "            pred += list(out_npy)    \n",
    "pred = np.array(pred)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred.max())\n",
    "print(pred.min())\n",
    "print(pred.mean())\n",
    "print((pred[:NUM_ITEMS*28]<1).sum()/pred[:NUM_ITEMS*28].shape[0])\n",
    "print((pred<1).sum()/pred.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape[0]/NUM_ITEMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/\"\n",
    "sample_submission = pd.read_csv(os.path.join(path, \"sample_submission.csv\"))\n",
    "test[\"demand\"] = pred.clip(0)\n",
    "submission = test.pivot(index=\"id\", columns=\"F\", values=\"demand\").reset_index()[sample_submission.columns]\n",
    "submission = sample_submission[[\"id\"]].merge(submission, how=\"left\", on=\"id\")\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"/home/timetraveller/Desktop/kek.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"/home/timetraveller/Desktop/kek.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -f /home/timetraveller/Desktop/kek.csv -m \"nn\" -c m5-forecasting-accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
