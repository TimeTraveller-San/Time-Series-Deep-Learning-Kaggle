{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# I am a big cheater\n",
    "# I am stealing code from here:\n",
    "https://github.com/SamLynnEvans/Transformer\n",
    "\n",
    "\n",
    "https://github.com/maxjcohen/transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import random \n",
    "\n",
    "import gc\n",
    "import pickle\n",
    "import math\n",
    "import datetime\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import time\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "device = torch.device('cuda')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "NUM_ITEMS = 30490\n",
    "DAYS_PRED = 28\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Make data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = \"../data\"\n",
    "calendar = pd.read_csv(os.path.join(path, \"calendar.csv\"))\n",
    "selling_prices = pd.read_csv(os.path.join(path, \"sell_prices.csv\"))\n",
    "sample_submission = pd.read_csv(os.path.join(path, \"sample_submission.csv\"))\n",
    "# sales = pd.read_csv(os.path.join(path, \"sales_train_validation.csv\"))\n",
    "sales = pd.read_csv(os.path.join(path, \"sales_train_evaluation.csv\")) #For final submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def prep_calendar(df):\n",
    "    df = df.drop([\"date\", \"weekday\"], axis=1)\n",
    "    df = df.assign(d = df.d.str[2:].astype(int))\n",
    "    df = df.fillna(\"missing\")\n",
    "    cols = list(set(df.columns) - {\"wm_yr_wk\", \"d\"})\n",
    "    df[cols] = OrdinalEncoder(dtype=\"int\").fit_transform(df[cols])\n",
    "    df = reduce_mem_usage(df)\n",
    "    return df\n",
    "\n",
    "calendar = prep_calendar(calendar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def prep_selling_prices(df):\n",
    "    gr = df.groupby([\"store_id\", \"item_id\"])[\"sell_price\"]\n",
    "    df[\"sell_price_rel_diff\"] = gr.pct_change()\n",
    "    df[\"sell_price_roll_sd7\"] = gr.transform(lambda x: x.rolling(7).std())\n",
    "    df[\"sell_price_roll_sd28\"] = gr.transform(lambda x: x.rolling(28).std())\n",
    "    df[\"sell_price_cumrel\"] = (gr.shift(0) - gr.cummin()) / (1 + gr.cummax() - gr.cummin())\n",
    "    df = reduce_mem_usage(df)\n",
    "    return df\n",
    "\n",
    "selling_prices = prep_selling_prices(selling_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dropd = 509\n",
    "(1969-dropd)/365 #Will use 4 years dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def reshape_sales(df, drop_d = None):\n",
    "    if drop_d is not None:\n",
    "        df = df.drop([\"d_\" + str(i + 1) for i in range(drop_d)], axis=1)\n",
    "        \n",
    "    df = df.assign(id=df.id.str.replace(\"_evaluation\", \"\"))\n",
    "    df = df.reindex(columns=df.columns.tolist() + [\"d_\" + str(1913 + 28 + i + 1) for i in range(28)])\n",
    "    df = df.melt(id_vars=[\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"],\n",
    "                 var_name='d', value_name='demand')\n",
    "    df = df.assign(d=df.d.str[2:].astype(\"int16\"))\n",
    "    return df\n",
    "\n",
    "sales = reshape_sales(sales, dropd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Applying functions in parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def long_sale_history_year(df):\n",
    "    gr = df.groupby(['id'])['demand']\n",
    "    for year in tqdm(range(1, 4)):\n",
    "        for d in [-3, -2, -1, 0, 1, 2, 3]: \n",
    "            shift = year * 365 + d\n",
    "            df[f'lag_year_{year}_{d}'] = gr.transform(lambda x: x.shift(shift))\n",
    "    df = reduce_mem_usage(df)    \n",
    "    return df\n",
    "\n",
    "sales = long_sale_history_year(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def long_sale_history_halfyear(df):\n",
    "    gr = df.groupby(['id'])['demand']\n",
    "    for year in tqdm(range(1, 4)):\n",
    "        for d in [-3, -2, -1, 0, 1, 2, 3]: \n",
    "            shift = year * (365//2) + d\n",
    "            df[f'lag_hyear_{year}_{d}'] = gr.transform(lambda x: x.shift(shift))\n",
    "    df = reduce_mem_usage(df)        \n",
    "    return df\n",
    "\n",
    "sales = long_sale_history_halfyear(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def long_sale_history_quarteryear(df):\n",
    "    gr = df.groupby(['id'])['demand']\n",
    "    for year in tqdm(range(1, 4)):\n",
    "        for d in [-3, -2, -1, 0, 1, 2, 3]: \n",
    "            shift = year * (365//4) + d\n",
    "            df[f'lag_qyear_{year}_{d}'] = gr.transform(lambda x: x.shift(shift))\n",
    "    df = reduce_mem_usage(df)         \n",
    "    return df\n",
    "\n",
    "sales = long_sale_history_quarteryear(sales)\n",
    "print(sales.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def long_price_history_year(df):\n",
    "#     gr = df.groupby(['id'])['sell_price']\n",
    "#     for year in tqdm(range(1, 4)):\n",
    "#         for d in [-3, -2, -1, 0, 1, 2, 3]: \n",
    "#             shift = year * 365 + d\n",
    "#             df[f'lag_year_{year}_{d}'] = gr.transform(lambda x: x.shift(shift))\n",
    "#     df = reduce_mem_usage(df)    \n",
    "#     return df\n",
    "\n",
    "# sales = long_sale_history_year(sales)\n",
    "\n",
    "# def long_price_history_halfyear(df):\n",
    "#     gr = df.groupby(['id'])['sell_price']\n",
    "#     for year in tqdm(range(1, 4)):\n",
    "#         for d in [-3, -2, -1, 0, 1, 2, 3]: \n",
    "#             shift = year * (365//2) + d\n",
    "#             df[f'lag_year_{year}_{d}'] = gr.transform(lambda x: x.shift(shift))\n",
    "#     df = reduce_mem_usage(df)    \n",
    "#     return df\n",
    "\n",
    "# sales = long_price_history_halfyear(sales)\n",
    "\n",
    "# def long_price_history_quarteryear(df):\n",
    "#     gr = df.groupby(['id'])['sell_price']\n",
    "#     for year in tqdm(range(1, 4)):\n",
    "#         for d in [-3, -2, -1, 0, 1, 2, 3]: \n",
    "#             shift = year * (365//4) + d\n",
    "#             df[f'lag_year_{year}_{d}'] = gr.transform(lambda x: x.shift(shift))\n",
    "#     df = reduce_mem_usage(df)    \n",
    "#     return df\n",
    "\n",
    "# sales = long_sale_history_year(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!rm temp.hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sales.iloc[-NUM_ITEMS*28*24:].to_hdf(\"/home/timetraveller/Work/temp_large.hdf\", key=\"ok\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!ls *hdf -alh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sales.iloc[-NUM_ITEMS*28*12:].to_hdf(\"temp.hdf\", key=\"ok\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sales = pd.read_hdf(\"temp.hdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(sales.shape)\n",
    "print(sales.shape[0]//NUM_ITEMS)\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sales = sales.merge(calendar, how=\"left\", on=\"d\")\n",
    "gc.collect()\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sales = sales.merge(selling_prices, how=\"left\", on=[\"wm_yr_wk\", \"store_id\", \"item_id\"])\n",
    "sales.drop([\"wm_yr_wk\"], axis=1, inplace=True)\n",
    "gc.collect()\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del selling_prices; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cat_id_cols = [\"item_id\", \"dept_id\", \"store_id\", \"cat_id\", \"state_id\"]\n",
    "cat_cols = cat_id_cols + [\"wday\", \"month\", \"year\", \"event_name_1\", \n",
    "                          \"event_type_1\", \"event_name_2\", \"event_type_2\"]\n",
    "\n",
    "for i, v in tqdm(enumerate(cat_id_cols)):\n",
    "    sales[v] = OrdinalEncoder(dtype=\"int\").fit_transform(sales[[v]])\n",
    "\n",
    "sales = reduce_mem_usage(sales)\n",
    "gc.collect()\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_cols_price = [\"sell_price\", \"sell_price_rel_diff\", \"sell_price_roll_sd7\", \"sell_price_roll_sd28\", \"sell_price_cumrel\"]\n",
    "\n",
    "lag_cols = []\n",
    "for lag in  ['year', 'hyear', 'qyear']:\n",
    "    for y in range(1, 4):\n",
    "        for t in [-3, -2, 1, 0, 1, 2,  3]:\n",
    "            lag_cols.append(f\"lag_{lag}_{y}_{t}\")\n",
    "\n",
    "bool_cols = [\"snap_CA\", \"snap_TX\", \"snap_WI\"]\n",
    "\n",
    "cont_cols = num_cols_price + lag_cols + bool_cols\n",
    "\n",
    "for i, v in enumerate(tqdm(cont_cols)):\n",
    "    sales[v] = sales[v].fillna(sales[v].median())\n",
    "    \n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sales.to_hdf(\"/home/timetraveller/Work/sales.hdf\", key=\"ok\", index=False)\n",
    "# sales= pd.read_hdf(\"/home/timetraveller/Work/sales.hdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_data(i, days, sales, train=False):\n",
    "    if train: start = 0 \n",
    "    else: start = (days + i*28)*NUM_ITEMS\n",
    "    end = i*28*NUM_ITEMS\n",
    "    print(start)\n",
    "    print(end)\n",
    "    if i == 0:\n",
    "        return sales.iloc[-start:]\n",
    "    return sales.iloc[-start:-end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "e_days = 28*4\n",
    "d_days = 28\n",
    "days = e_days + d_days\n",
    "test = make_data(0, days, sales)\n",
    "val = make_data(1, days, sales)\n",
    "train = make_data(2, days, sales, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(train.shape[0]/NUM_ITEMS)\n",
    "\n",
    "print(val.shape)\n",
    "print(val.shape[0]/NUM_ITEMS)\n",
    "\n",
    "print(test.shape)\n",
    "print(test.shape[0]/NUM_ITEMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\">> train\")\n",
    "for col in train.columns:\n",
    "    if train[col].isna().any():\n",
    "        print(col)\n",
    "        \n",
    "print(\">> val\")\n",
    "for col in val.columns:\n",
    "    if val[col].isna().any():\n",
    "        print(col)    \n",
    "        \n",
    "print(\">> test\")\n",
    "for col in test.columns:\n",
    "    if test[col].isna().any():\n",
    "        print(col)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save(x, fname):\n",
    "    with open(fname, \"wb\") as handle:\n",
    "        pickle.dump(x, handle)\n",
    "        \n",
    "save(train, \"train_all.data\")        \n",
    "save(val, \"val.data\")        \n",
    "save(test, \"test.data\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load(fname):\n",
    "    with open(fname, \"rb\") as handle:\n",
    "        return pickle.load(handle)\n",
    "    \n",
    "# train = load(\"train.data\")    \n",
    "train = load(\"train_all.data\")    \n",
    "val = load(\"val.data\")    \n",
    "test = load(\"test.data\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# save(train, \"train.data\")        \n",
    "# save(test, \"test.data\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Cat cols: 5\n",
      "# Id cols: 5\n",
      "# Cont cols: 8\n",
      "# Lag cols: 63\n"
     ]
    }
   ],
   "source": [
    "id_cols = ['item_id', 'dept_id', 'store_id', 'cat_id', 'state_id']\n",
    "cat_cols = ['wday', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
    "\n",
    "num_cols_price = [\"sell_price\", \"sell_price_rel_diff\", \"sell_price_roll_sd7\", \"sell_price_roll_sd28\", \"sell_price_cumrel\"]\n",
    "\n",
    "lag_cols = []\n",
    "for lag in  ['year', 'hyear', 'qyear']:\n",
    "    for y in range(1, 4):\n",
    "        for t in [-3, -2, 1, 0, 1, 2,  3]:\n",
    "            lag_cols.append(f\"lag_{lag}_{y}_{t}\")\n",
    "\n",
    "bool_cols = [\"snap_CA\", \"snap_TX\", \"snap_WI\"]\n",
    "\n",
    "cont_cols = num_cols_price + bool_cols\n",
    "\n",
    "print(f\"# Cat cols: {len(cat_cols)}\")\n",
    "print(f\"# Id cols: {len(id_cols)}\")\n",
    "print(f\"# Cont cols: {len(cont_cols)}\")\n",
    "print(f\"# Lag cols: {len(lag_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min max scaling cont and lag data.....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23a1b3b05369446ba420dbc947fcfa51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=71), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Min max scaling cont and lag data.....\")\n",
    "for col in tqdm(cont_cols + lag_cols):\n",
    "    maxval = train[col].max()\n",
    "    minval = train[col].min()\n",
    "    if maxval == minval:\n",
    "        denom = 1\n",
    "    else:\n",
    "        denom = maxval-minval\n",
    "    \n",
    "    train[col] = (train[col]-minval)/denom\n",
    "    val[col] = (val[col]-minval)/denom\n",
    "    test[col] = (test[col]-minval)/denom\n",
    "    gc.collect()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280\n",
      "140\n",
      "140\n"
     ]
    }
   ],
   "source": [
    "TARGET = 'demand'\n",
    "print(train.shape[0]//NUM_ITEMS)\n",
    "print(val.shape[0]//NUM_ITEMS)\n",
    "print(test.shape[0]//NUM_ITEMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train\n",
      ">> val\n",
      ">> test\n",
      "demand\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "print(\">> train\")\n",
    "for col in train.columns:\n",
    "    if train[col].isna().any():\n",
    "        print(col)\n",
    "        \n",
    "print(\">> val\")\n",
    "for col in val.columns:\n",
    "    if val[col].isna().any():\n",
    "        print(col)    \n",
    "        \n",
    "print(\">> test\")\n",
    "for col in test.columns:\n",
    "    if test[col].isna().any():\n",
    "        print(col)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     3
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
    "\n",
    "class M5Dataset_train(Dataset):\n",
    "    def __init__(self, X, cont_cols, cat_cols, id_cols, lag_cols, \n",
    "                             target='demand', e_days=28*4, d_days=28):\n",
    "        \n",
    "        self.e_days = e_days\n",
    "        self.d_days = d_days\n",
    "        cat_cols = id_cols + cat_cols \n",
    "        self.cat_cols = cat_cols\n",
    "        \n",
    "        self.X_cont = X[cont_cols].values\n",
    "        self.X_cat = X[cat_cols].values\n",
    "        self.X_lags = X[lag_cols].values\n",
    "        self.ids = X[id_cols].values\n",
    "        self.y = X[target].values\n",
    "        \n",
    "        x_days = X.shape[0]//NUM_ITEMS\n",
    "        total_days = x_days - e_days - d_days\n",
    "        self.len = int(NUM_ITEMS * total_days)\n",
    "        self.total_days = total_days\n",
    "        print(f\"total_days: {total_days}\")\n",
    "        print(f\"len: {self.len}\")\n",
    "\n",
    "    def get_ti(self, idx):\n",
    "        time, item = divmod(idx, NUM_ITEMS)\n",
    "        return time, item\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        time, item = self.get_ti(idx)\n",
    "        e_start_day = time\n",
    "        e_end_day = time + self.e_days\n",
    "        d_start_day = time + self.e_days\n",
    "        d_end_day = time + self.e_days + self.d_days\n",
    "        \n",
    "        e_idxes = item + np.arange(e_start_day, e_end_day)*NUM_ITEMS\n",
    "        d_idxes = item + np.arange(d_start_day, d_end_day)*NUM_ITEMS\n",
    "\n",
    "        #Encoding cat and cont information\n",
    "        encoder_cont = np.concatenate([self.X_cont[e_idxes],\n",
    "                                                                          self.y[e_idxes].reshape(-1, 1)], \n",
    "                                                                          axis=1)\n",
    "        encoder_cat = self.X_cat[e_idxes]\n",
    "        encoder_lags = self.X_lags[e_idxes]\n",
    "        enc_hist = self.y[e_idxes]\n",
    "        \n",
    "        #Decoding cat and cont information\n",
    "        decoder_cont = self.X_cont[d_idxes]\n",
    "        decoder_cat = self.X_cat[d_idxes]\n",
    "        decoder_lags = self.X_lags[d_idxes]\n",
    "        \n",
    "        #Labels\n",
    "        labels = self.y[d_idxes]\n",
    "        #Id (same for all timesteps)\n",
    "        ids = self.ids[idx]\n",
    "        return (enc_hist, encoder_cont, encoder_cat, encoder_lags, \n",
    "                        decoder_cont, decoder_cat, decoder_lags), idx, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"e_cont, e_cat, d_cont, d_cat, ids, y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     3
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class M5Dataset(Dataset):\n",
    "    def __init__(self, X, cont_cols, cat_cols, id_cols, lag_cols, \n",
    "                             target='demand', e_days=28*4, d_days=28):\n",
    "        \n",
    "        self.e_days = e_days\n",
    "        self.d_days = d_days\n",
    "        cat_cols = id_cols + cat_cols \n",
    "        self.cat_cols = cat_cols\n",
    "        \n",
    "        self.X_cont = X.iloc[-NUM_ITEMS*(e_days+d_days):][cont_cols].values\n",
    "        self.X_cat = X.iloc[-NUM_ITEMS*(e_days+d_days):][cat_cols].values\n",
    "        self.X_lags = X.iloc[-NUM_ITEMS*(e_days+d_days):][lag_cols].values\n",
    "        self.ids = X.iloc[-NUM_ITEMS*(e_days+d_days):][id_cols].values\n",
    "        self.y = X.iloc[-NUM_ITEMS*(e_days+d_days):][target].values\n",
    "        \n",
    "        self.len = NUM_ITEMS\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = idx\n",
    "        e_start_day = 0\n",
    "        e_end_day = self.e_days\n",
    "        d_start_day = self.e_days\n",
    "        d_end_day = self.e_days  + self.d_days      \n",
    "        \n",
    "        \n",
    "        e_idxes = item + np.arange(e_start_day, e_end_day)*NUM_ITEMS\n",
    "        d_idxes = item + np.arange(d_start_day, d_end_day)*NUM_ITEMS\n",
    "\n",
    "        #Encoding cat and cont information\n",
    "        encoder_cont = np.concatenate([self.X_cont[e_idxes],\n",
    "                                                                          self.y[e_idxes].reshape(-1, 1)], \n",
    "                                                                          axis=1)\n",
    "        encoder_cat = self.X_cat[e_idxes]\n",
    "        encoder_lags = self.X_lags[e_idxes]\n",
    "        enc_hist = self.y[e_idxes]\n",
    "        \n",
    "        #Decoding cat and cont information\n",
    "        decoder_cont = self.X_cont[d_idxes]\n",
    "        decoder_cat = self.X_cat[d_idxes]\n",
    "        decoder_lags = self.X_lags[d_idxes]\n",
    "        \n",
    "        #Labels\n",
    "        labels = self.y[d_idxes]\n",
    "        #Id (same for all timesteps)\n",
    "        ids = self.ids[idx]\n",
    "        return (enc_hist, encoder_cont, encoder_cat, encoder_lags, \n",
    "                        decoder_cont, decoder_cat, decoder_lags), idx, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"e_cont, e_cat, d_cont, d_cat, ids, y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_days: 140\n",
      "len: 4268600\n"
     ]
    }
   ],
   "source": [
    "bs = 128\n",
    "shuffle = True\n",
    "num_workers = 4\n",
    "e_days = 28*4 #Can't be more than 28*4 for now\n",
    "d_days = 28\n",
    "\n",
    "\n",
    "train_dataset = M5Dataset_train(train, cont_cols, cat_cols, id_cols, lag_cols, \n",
    "                                                 e_days=e_days, d_days=d_days)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=bs,\n",
    "                                    shuffle=shuffle, num_workers=num_workers)\n",
    "\n",
    "val_dataset = M5Dataset(val, cont_cols, cat_cols, id_cols, lag_cols, \n",
    "                                                 e_days=e_days, d_days=d_days)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=bs,\n",
    "                                    shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "4268600\n",
      "33349\n",
      "torch.Size([128, 112])\n",
      "torch.Size([128, 112, 9])\n",
      "torch.Size([128, 112, 10])\n",
      "torch.Size([128, 112, 63])\n",
      "torch.Size([128, 28, 8])\n",
      "torch.Size([128, 28, 10])\n",
      "torch.Size([128, 28, 63])\n",
      "tensor([2505276, 2424199, 2201900, 2167290, 1523832, 2294929, 4194292, 2507456,\n",
      "        4091034, 2529923, 1889000,  370847, 2258095, 3290940, 3543385, 3200655,\n",
      "        1916775, 3891441, 3038127, 3245359, 3865593, 1972778, 2514135, 1516548,\n",
      "        2782877, 3344794, 4051845, 1480392, 2299152, 1280318,  528085, 1860425,\n",
      "           7861,  469628, 2632129,  875416,  130416,   88783, 2722594, 1428339,\n",
      "        1523217, 4073846, 4064255, 3330863, 2683579,  903469, 3808007,  713401,\n",
      "         149038,  909036, 3882420, 3538974, 1780822, 1351569,  347853, 2783834,\n",
      "        3150010, 1126270, 1306162, 2216645, 2475260, 1231454, 1939562, 1481643,\n",
      "        3249043,  154605, 2611563, 3314850, 1723729, 3429861, 2136074,  278160,\n",
      "        1182876, 1383218, 2012669, 2213532, 3753026, 2119267, 3390608, 3312397,\n",
      "        1045756, 1526062, 2568052, 1873615, 4077849, 2066218, 1638001, 1560241,\n",
      "        2682623,  184276, 2745325, 3377337, 1245549,  984775,  424555,  938079,\n",
      "           2213, 2166068, 2544918, 2165305, 4008737, 2317828, 1386709, 2564115,\n",
      "        1607909, 1732272, 2596057, 3341162, 2527719, 2416995,  176891, 4194135,\n",
      "         847966,  279064, 2167964,  577549, 1488959, 3303318,  379895, 4086324,\n",
      "         140297,  176070, 3758448, 1675772, 4129581, 1050892, 2894997, 3423848])\n",
      "\n",
      "Val\n",
      "30490\n",
      "239\n",
      "torch.Size([128, 112])\n",
      "torch.Size([128, 112, 9])\n",
      "torch.Size([128, 112, 10])\n",
      "torch.Size([128, 112, 63])\n",
      "torch.Size([128, 28, 8])\n",
      "torch.Size([128, 28, 10])\n",
      "torch.Size([128, 28, 63])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train\")\n",
    "print(len(train_dataset))\n",
    "print(len(train_loader))\n",
    "\n",
    "for i, (x, idx, y) in enumerate(train_loader):\n",
    "    for _x in x:\n",
    "        print(_x.shape)\n",
    "    print(idx)    \n",
    "    break\n",
    "    \n",
    "print(\"\\nVal\")\n",
    "print(len(val_dataset))\n",
    "print(len(val_loader))\n",
    "\n",
    "for i, (x, idx, y) in enumerate(val_loader):\n",
    "    for _x in x:\n",
    "        print(_x.shape)\n",
    "    print(idx)    \n",
    "    break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i, (x, idx, y) in enumerate(tqdm(train_loader)):\n",
    "#     continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     2,
     12,
     22,
     34,
     43,
     54,
     57,
     61,
     67,
     73
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "calc_wrmsse = True\n",
    "\n",
    "class MSE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_true = y_true.type(torch.FloatTensor).to(device).flatten()\n",
    "        y_pred = y_pred.flatten()\n",
    "        return self.mse(y_pred, y_true)\n",
    "\n",
    "class RMSE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_true = y_true.type(torch.FloatTensor).to(device).flatten()\n",
    "        y_pred = y_pred.flatten()\n",
    "        return torch.sqrt(self.mse(y_pred, y_true))    \n",
    "    \n",
    "class Assymetric_RMSE(nn.Module):\n",
    "    def __init__(self, penalty=3.5):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.penalty = penalty\n",
    "        \n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_true = y_true.type(torch.FloatTensor).to(device).flatten()\n",
    "        y_pred = y_pred.flatten()\n",
    "        error = torch.where(y_true==0, self.penalty*(y_true-y_pred)**2, (y_true-y_pred)**2)\n",
    "        return torch.sqrt(torch.mean(error))\n",
    "\n",
    "class MAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_true = y_true.type(torch.FloatTensor).to(device).flatten()\n",
    "        y_pred = y_pred.flatten()\n",
    "        return torch.mean(torch.abs(y_pred-y_true))        \n",
    "    \n",
    "if calc_wrmsse:\n",
    "    roll_mat_df = pd.read_pickle('../data/roll_mat_df.pkl')\n",
    "    roll_index = roll_mat_df.index\n",
    "    roll_mat_csr = csr_matrix(roll_mat_df.values)\n",
    "    del roll_mat_df; gc.collect()\n",
    "\n",
    "    sw_df = pd.read_pickle('../data/sw_df.pkl')\n",
    "    s = sw_df.s.values\n",
    "    w = sw_df.w.values\n",
    "    sw = sw_df.sw.values   \n",
    "    \n",
    "def rollup(v, roll_mat_csr):\n",
    "    return roll_mat_csr*v #(v.T*roll_mat_csr.T).T\n",
    "\n",
    "def wrmsse_metric(preds, y_true, score_only=True, npy=True, roll_mat_csr=None, sw=None, roll_index=roll_index, verbose=False, s=s, w=w):\n",
    "    preds = np.array(preds).reshape(NUM_ITEMS, -1)\n",
    "    y_true = np.array(y_true).reshape(NUM_ITEMS, -1)\n",
    "\n",
    "    if roll_mat_csr is None:\n",
    "        roll_mat_df = pd.read_pickle('../data/roll_mat_df.pkl')\n",
    "        roll_index = roll_mat_df.index\n",
    "        roll_mat_csr = csr_matrix(roll_mat_df.values)\n",
    "        del roll_mat_df; gc.collect()\n",
    "\n",
    "    if sw is None:\n",
    "        sw_df = pd.read_pickle('../data/sw_df.pkl')\n",
    "        s = sw_df.s.values\n",
    "        w = sw_df.w.values\n",
    "        sw = sw_df.sw.values\n",
    "\n",
    "    if not npy:\n",
    "        preds = preds.values\n",
    "        y_true = y_true.values\n",
    "    \n",
    "    if score_only:\n",
    "        return np.sum(\n",
    "                np.sqrt(\n",
    "                    np.mean(\n",
    "                        np.square(rollup(preds-y_true, roll_mat_csr))\n",
    "                            ,axis=1)) * sw)/12 \n",
    "    else: \n",
    "        score_matrix = (np.square(rollup(preds-y_true, roll_mat_csr)) * np.square(w)[:, None])/ s[:, None]\n",
    "        score = np.sum(np.sqrt(np.mean(score_matrix, axis=1)))/12 \n",
    "        \n",
    "        score_df = pd.DataFrame(score_matrix, index = roll_index)\n",
    "        score_df.reset_index(inplace=True)\n",
    "        score_df['mean_err'] = score_df.mean(axis=1)\n",
    "        level_wise_error1 = score_df.groupby('level')['mean_err'].mean()\n",
    "        \n",
    "        return score, level_wise_error1.values\n",
    "\n",
    "def rmse_metric(y_pred, y_true):\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    return np.sqrt(np.mean((y_pred-y_true)**2))                                \n",
    "\n",
    "def rmse_metric_npy(y_pred, y_true):\n",
    "    return np.sqrt(np.mean((y_pred-y_true)**2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class WRMSSE(nn.Module):\n",
    "    def __init__(self, roll_mat_csr=roll_mat_csr, sw=sw):\n",
    "        super().__init__()\n",
    "        roll_mat_coo = roll_mat_csr.tocoo()\n",
    "        self.rollTensor = torch.sparse.LongTensor(torch.LongTensor([roll_mat_coo.row.tolist(), roll_mat_coo.col.tolist()]),\n",
    "                              torch.LongTensor(roll_mat_coo.data.astype(np.int32))).type(torch.FloatTensor).to_dense()\n",
    "        self.sw_t = torch.FloatTensor(sw).to(device)\n",
    "\n",
    "    def forward(self, y_pred, y_true, idxes):\n",
    "        _bs = y_true.shape[0]\n",
    "        idxes = list(idxes.numpy())\n",
    "        y_true = y_true.type(torch.FloatTensor).to(device).flatten().view(_bs, -1)\n",
    "        y_pred = y_pred.flatten().view(_bs, -1)\n",
    "        \n",
    "        residual = y_true-y_pred\n",
    "        \n",
    "        loss = torch.sum(torch.sqrt(\n",
    "                    torch.mean((\n",
    "                        torch.mm(self.rollTensor[:, idxes].to(device), residual)**2), axis=1)+1e-8 \n",
    "                    )*self.sw_t)/12        \n",
    "        return 1e4*loss #Dont want gradients too small  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class WeightedRoll_MSE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.sw_t = torch.FloatTensor(sw[:, np.newaxis]).to(device)\n",
    "        roll_mat_coo = roll_mat_csr.tocoo()\n",
    "        self.rollTensor = torch.sparse.LongTensor(torch.LongTensor([roll_mat_coo.row.tolist(), roll_mat_coo.col.tolist()]),\n",
    "                              torch.LongTensor(roll_mat_coo.data.astype(np.int32))).type(torch.FloatTensor).to_dense()\n",
    "        \n",
    "    def rollup(self, x):\n",
    "        return torch.mm(self.rollTensor, x)\n",
    "        \n",
    "    def forward(self, y_pred, y_true, i):\n",
    "        _bs = y_true.shape[0]\n",
    "        idxes = np.arange(i*bs, i*bs+_bs)\n",
    "        \n",
    "        y_true = y_true.type(torch.FloatTensor).to(device).flatten().view(_bs, -1)\n",
    "        y_pred = y_pred.flatten().view(_bs, -1)\n",
    "        \n",
    "        error1 = self.mse(y_pred, y_true)\n",
    "        partial_roll_t = self.rollTensor[:, idxes].to(device)\n",
    "        \n",
    "        y_pred = torch.mm(partial_roll_t, y_pred)\n",
    "        y_true = torch.mm(partial_roll_t, y_true)\n",
    "        y_pred = (self.sw_t*y_pred).flatten()\n",
    "        y_true = (self.sw_t*y_true).flatten()\n",
    "        error2 = 1e8*self.mse(y_pred, y_true)\n",
    "        \n",
    "        return error1 + error2 #Dont want gradients to be too small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class RMSE_summed(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_true = y_true.type(torch.FloatTensor).to(device).flatten()\n",
    "        y_pred = y_pred.flatten()\n",
    "        n = y_true.shape[0]+1 #1 for sum of all        \n",
    "        error1 = self.mse(y_true, y_pred)\n",
    "        true_sum = torch.sum(y_true)\n",
    "        pred_sum = torch.sum(y_pred)\n",
    "        residual = torch.abs(true_sum-pred_sum)\n",
    "        error2 = residual/n\n",
    "        \n",
    "#         error1 = torch.sum((torch.log1p(y_true) - torch.log1p(y_pred))**2)/n\n",
    "#         error2 = (torch.log1p(torch.sum(y_true)) - torch.log1p(torch.sum(y_pred)))**2/n\n",
    "        return error1 + error2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tst.encoder import Encoder\n",
    "from tst.decoder import Decoder\n",
    "from tst.utils import generate_original_PE, generate_regular_PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniques = [3049, 7, 10, 3, 3, 7, 31, 5, 5, 5]\n",
    "# # dims = [5, 1, 2, 1, 1, 1, 2, 1, 1, 1]\n",
    "# dims = [7, 2, 3, 1, 1, 1, 3, 1, 1, 1]\n",
    "# emb_dims = [(x, y) for x, y in zip(uniques, dims)]\n",
    "# print(emb_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3049, 16), (7, 2), (10, 3), (3, 1), (3, 1), (7, 2), (31, 4), (5, 2), (5, 2), (5, 2)]\n"
     ]
    }
   ],
   "source": [
    "uniques = [3049, 7, 10, 3, 3, 7, 31, 5, 5, 5]\n",
    "# dims = [5, 1, 2, 1, 1, 1, 2, 1, 1, 1]\n",
    "dims = [16, 2, 3, 1, 1, 2, 4, 2, 2, 2]\n",
    "emb_dims = [(x, y) for x, y in zip(uniques, dims)]\n",
    "print(emb_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "class ConvModule(nn.Module):\n",
    "    def __init__(self, seq_len=56):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.global_conv = nn.Conv1d(1, 2, kernel_size=(seq_len))\n",
    "        self.week_conv = nn.Conv1d(1, 1, kernel_size=(7))\n",
    "        self.last_week_conv = nn.Conv1d(1, 1, kernel_size=(7))\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x[:, None, :] #insert 1 channel (bs, channel, timesteps)\n",
    "        bs = x.shape[0]\n",
    "        \n",
    "        out1 = self.global_conv(x).view(bs, -1).view(bs, -1)\n",
    "        out1 = self.drop(out1)\n",
    "        \n",
    "        out2 = self.week_conv(x).view(bs, -1).view(bs, -1)\n",
    "        out2 = self.drop(out2)\n",
    "        \n",
    "        out3 = self.last_week_conv(x[:, :, -7:]).view(bs, -1)\n",
    "        out3 = self.drop(out3)     \n",
    "        \n",
    "        out = torch.cat([out1, out2, out3], axis=1)\n",
    "        return out\n",
    "\n",
    "class M5Transformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 d_input: int,\n",
    "                 d_model: int,\n",
    "                 d_output: int,\n",
    "                 q: int,\n",
    "                 v: int,\n",
    "                 h: int,\n",
    "                 N_e: int,\n",
    "                 N_d: int,\n",
    "                 n_months: int,\n",
    "                 attention_size: int = None,\n",
    "                 dropout: float = 0.3,\n",
    "                 chunk_mode: bool = True,\n",
    "                 pe: str = None,\n",
    "                 n_lag_convs=3,\n",
    "                 e_days = 28*4,\n",
    "                 d_days = 28):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self._d_model = d_model\n",
    "        self._inp_dropout = nn.Dropout(0.1)\n",
    "\n",
    "        self.emb_layers = nn.ModuleList([nn.Embedding(x, y) for x, y in emb_dims])\n",
    "        self._lag_per_time = nn.Linear(63, n_lag_convs)\n",
    "        \n",
    "        self._e_inp_norm = nn.LayerNorm(d_input+n_lag_convs)\n",
    "        self._d_inp_norm = nn.LayerNorm(d_input+n_lag_convs-1)\n",
    "\n",
    "        self._embedding = nn.Linear(d_input, d_model)\n",
    "        \n",
    "        self.enc_embedding = nn.Linear(d_input+n_lag_convs, d_model)\n",
    "        self.dec_embedding = nn.Linear(d_input-1+n_lag_convs, d_model)\n",
    "        \n",
    "        self.layers_encoding = nn.ModuleList([Encoder(d_model,\n",
    "                                                      q,\n",
    "                                                      v,\n",
    "                                                      h,\n",
    "                                                      attention_size=attention_size,\n",
    "                                                      dropout=dropout,\n",
    "                                                      chunk_mode=chunk_mode) for _ in range(N_e)])\n",
    "        \n",
    "        self.layers_decoding = nn.ModuleList([Decoder(d_model,\n",
    "                                                      q,\n",
    "                                                      v,\n",
    "                                                      h,\n",
    "                                                      n_months,\n",
    "                                                      attention_size=attention_size,\n",
    "                                                      dropout=dropout,\n",
    "                                                      chunk_mode=chunk_mode) for _ in range(N_d)])\n",
    "\n",
    "        self.hist_covs = ConvModule(e_days)\n",
    "        out_dim = 237\n",
    "        self.out = nn.Sequential(\n",
    "                                        nn.Linear(out_dim, out_dim//2),\n",
    "                                        nn.LeakyReLU(),\n",
    "                                        nn.LayerNorm(out_dim//2),\n",
    "                                        nn.Linear(out_dim//2, d_output),\n",
    "                                    )\n",
    "        \n",
    "#         self.out = nn.Linear(out_dim, d_output)\n",
    "        \n",
    "        pe_functions = {\n",
    "            'original': generate_original_PE,\n",
    "            'regular': generate_regular_PE,\n",
    "        }\n",
    "\n",
    "        if pe in pe_functions.keys():\n",
    "            self._generate_PE = pe_functions[pe]\n",
    "        elif pe is None:\n",
    "            self._generate_PE = None\n",
    "        else:\n",
    "            raise NameError(\n",
    "                f'PE \"{pe}\" not understood. Must be one of {\", \".join(pe_functions.keys())} or None.')\n",
    "\n",
    "#     def lag_features(self, lag):\n",
    "#         bs, t, nf = lag.shape\n",
    "#         lag_features = []        \n",
    "#         for i in range(t):\n",
    "#                 _x = lag[:, i, :].reshape(bs, nf, -1)\n",
    "#                 feats = [lc(_x) for lc in self._lag_convs]\n",
    "#                 lag_features.append(torch.cat(feats, dim=2))\n",
    "#         return torch.cat(lag_features, dim=1)\n",
    "                \n",
    "    def embed_and_combine(self, cont, cat, lag):\n",
    "        cat = cat.type(torch.LongTensor).to(device)\n",
    "        cont = cont.type(torch.FloatTensor).to(device)\n",
    "        lag = lag.type(torch.FloatTensor).to(device)                \n",
    "        xcat = [el(cat[:, :, k]) for k, el in enumerate(self.emb_layers)]\n",
    "        xcat = torch.cat(xcat, axis=2)\n",
    "        xlags = self._lag_per_time(lag)        \n",
    "        combined = torch.cat([xcat, cont, xlags], axis=2) \n",
    "        combined = self._inp_dropout(combined)  \n",
    "        return combined \n",
    "\n",
    "                \n",
    "    def forward(self, x):\n",
    "        hist, e_cont, e_cat, e_lag, d_cont, d_cat, d_lag = x        \n",
    "                \n",
    "        encoder_input = self.embed_and_combine(e_cont, e_cat, e_lag) #(bs, etime, d_inp)\n",
    "        encoder_input = self._e_inp_norm(encoder_input)\n",
    "        decoder_input = self.embed_and_combine(d_cont, d_cat, d_lag) #(bs, etime, d_inp-1)\n",
    "        decoder_input = self._d_inp_norm(decoder_input)\n",
    "                \n",
    "        bs = encoder_input.shape[0]         \n",
    "        Ke = encoder_input.shape[1]\n",
    "        Kd = decoder_input.shape[1]\n",
    "\n",
    "        # Embedding module\n",
    "        encoding = self.enc_embedding(encoder_input)        \n",
    "\n",
    "        # Add position encoding\n",
    "        if self._generate_PE is not None:\n",
    "            positional_encoding = self._generate_PE(Ke, self._d_model)\n",
    "            positional_encoding = positional_encoding.to(encoding.device)\n",
    "            encoding.add_(positional_encoding)\n",
    "\n",
    "        # Encoding stack\n",
    "        for layer in self.layers_encoding:\n",
    "            encoding = layer(encoding)\n",
    "\n",
    "        # Decoding stack\n",
    "        decoding = self.dec_embedding(decoder_input)        \n",
    "#         decoding = encoding        \n",
    "\n",
    "        # Add position encoding\n",
    "        if self._generate_PE is not None:\n",
    "            positional_encoding = self._generate_PE(Kd, self._d_model)\n",
    "            positional_encoding = positional_encoding.to(decoding.device)\n",
    "            decoding.add_(positional_encoding)\n",
    "                \n",
    "        for layer in self.layers_decoding:\n",
    "            decoding = layer(decoding, encoding)\n",
    "\n",
    "        # Output module\n",
    "        _hist = self.hist_covs(hist.type(torch.FloatTensor).to(device))       \n",
    "        _hist = _hist.unsqueeze(1).repeat(1, 28, 1)        \n",
    "        output = self.out(torch.cat([decoding, _hist], 2))\n",
    "#         output = F.relu(output)\n",
    "        return output.reshape(bs, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_input = 44 \n",
    "d_model = 64 \n",
    "d_output = 1\n",
    "q = 8  \n",
    "v = 8  \n",
    "h = 1 # Number of heads\n",
    "N_e = 2 # Number of encoders to stack\n",
    "N_d = 1 # Number of decoders to stack\n",
    "attention_size = 12  \n",
    "n_months = e_days // d_days\n",
    "dropout = 0.2 \n",
    "# pe = 'original'\n",
    "pe = None\n",
    "chunk_mode = None\n",
    "n_lag_convs = 9 #over 63 past lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = RMSE()\n",
    "# criterion = WRMSSE()\n",
    "# criterion = Assymetric_RMSE(penalty=3.5)\n",
    "# criterion = WeightedRoll_MSE()\n",
    "model = M5Transformer(d_input, d_model, d_output, q, v, h, N_e, N_d, n_months, attention_size=attention_size,\n",
    "                  dropout=dropout, chunk_mode=chunk_mode, pe=pe, n_lag_convs=n_lag_convs, e_days=e_days,\n",
    "                     d_days=d_days).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M5Transformer(\n",
       "  (_inp_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (emb_layers): ModuleList(\n",
       "    (0): Embedding(3049, 16)\n",
       "    (1): Embedding(7, 2)\n",
       "    (2): Embedding(10, 3)\n",
       "    (3): Embedding(3, 1)\n",
       "    (4): Embedding(3, 1)\n",
       "    (5): Embedding(7, 2)\n",
       "    (6): Embedding(31, 4)\n",
       "    (7): Embedding(5, 2)\n",
       "    (8): Embedding(5, 2)\n",
       "    (9): Embedding(5, 2)\n",
       "  )\n",
       "  (_lag_per_time): Linear(in_features=63, out_features=9, bias=True)\n",
       "  (_e_inp_norm): LayerNorm((53,), eps=1e-05, elementwise_affine=True)\n",
       "  (_d_inp_norm): LayerNorm((52,), eps=1e-05, elementwise_affine=True)\n",
       "  (_embedding): Linear(in_features=44, out_features=64, bias=True)\n",
       "  (enc_embedding): Linear(in_features=53, out_features=64, bias=True)\n",
       "  (dec_embedding): Linear(in_features=52, out_features=64, bias=True)\n",
       "  (layers_encoding): ModuleList(\n",
       "    (0): Encoder(\n",
       "      (_selfAttention): MultiHeadAttention(\n",
       "        (_W_q): Linear(in_features=64, out_features=8, bias=True)\n",
       "        (_W_k): Linear(in_features=64, out_features=8, bias=True)\n",
       "        (_W_v): Linear(in_features=64, out_features=8, bias=True)\n",
       "        (_W_o): Linear(in_features=8, out_features=64, bias=True)\n",
       "      )\n",
       "      (_feedForward): PositionwiseFeedForward(\n",
       "        (_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
       "        (_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (act): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (_layerNorm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (_layerNorm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (_dopout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (1): Encoder(\n",
       "      (_selfAttention): MultiHeadAttention(\n",
       "        (_W_q): Linear(in_features=64, out_features=8, bias=True)\n",
       "        (_W_k): Linear(in_features=64, out_features=8, bias=True)\n",
       "        (_W_v): Linear(in_features=64, out_features=8, bias=True)\n",
       "        (_W_o): Linear(in_features=8, out_features=64, bias=True)\n",
       "      )\n",
       "      (_feedForward): PositionwiseFeedForward(\n",
       "        (_linear1): Linear(in_features=64, out_features=128, bias=True)\n",
       "        (_linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (act): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (_layerNorm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (_layerNorm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (_dopout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (layers_decoding): ModuleList(\n",
       "    (0): Decoder(\n",
       "      (_mwa): MonthlyWeightedAvg(\n",
       "        (_conv): Conv1d(4, 1, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (_selfAttention): MultiHeadAttention(\n",
       "        (_W_q): Linear(in_features=64, out_features=8, bias=True)\n",
       "        (_W_k): Linear(in_features=64, out_features=8, bias=True)\n",
       "        (_W_v): Linear(in_features=64, out_features=8, bias=True)\n",
       "        (_W_o): Linear(in_features=8, out_features=64, bias=True)\n",
       "      )\n",
       "      (_encoderDecoderAttention): MultiHeadAttention(\n",
       "        (_W_q): Linear(in_features=64, out_features=8, bias=True)\n",
       "        (_W_k): Linear(in_features=64, out_features=8, bias=True)\n",
       "        (_W_v): Linear(in_features=64, out_features=8, bias=True)\n",
       "        (_W_o): Linear(in_features=8, out_features=64, bias=True)\n",
       "      )\n",
       "      (_feedForward): PositionwiseFeedForward(\n",
       "        (_linear1): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (_linear2): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (act): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (_layerNorm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (_layerNorm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (_layerNorm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (_dopout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (hist_covs): ConvModule(\n",
       "    (global_conv): Conv1d(1, 2, kernel_size=(112,), stride=(1,))\n",
       "    (week_conv): Conv1d(1, 1, kernel_size=(7,), stride=(1,))\n",
       "    (last_week_conv): Conv1d(1, 1, kernel_size=(7,), stride=(1,))\n",
       "    (drop): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): Linear(in_features=237, out_features=118, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): LayerNorm((118,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): Linear(in_features=118, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.6505, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor([[ 0.0050,  0.4040,  0.4009,  ...,  0.0900,  0.4664,  0.2797],\n",
      "        [-0.7214, -0.5164, -0.6644,  ..., -0.7101, -0.7622, -0.4803],\n",
      "        [ 0.3029,  0.4449,  0.3808,  ...,  0.4500,  0.4348,  0.5272],\n",
      "        ...,\n",
      "        [-0.3218,  0.0637,  0.2095,  ...,  0.0560,  0.1366,  0.5747],\n",
      "        [-0.2965, -0.2245, -0.4016,  ..., -0.5196, -0.4404, -0.5786],\n",
      "        [ 0.2930,  0.1033,  0.5227,  ...,  0.4866,  0.1350,  0.5427]],\n",
      "       device='cuda:0', grad_fn=<AsStridedBackward>)\n"
     ]
    }
   ],
   "source": [
    "# criterion = WRMSSE()\n",
    "criterion = RMSE()\n",
    "for i, (x, idx, y) in enumerate(train_loader):\n",
    "    out = model(x)\n",
    "#     loss = criterion(out, y, idx)\n",
    "    loss = criterion(out, y)\n",
    "    loss.backward()\n",
    "    break\n",
    "print(loss)    \n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "lr = 3e-4\n",
    "# criterion = Assymetric_RMSE(penalty=1/3.5)\n",
    "# criterion = Assymetric_RMSE(penalty=3.5)\n",
    "# criterion = WRMSSE() #WARNING! RAM EXPLOSION HERE\n",
    "# criterion = RMSE_summed()\n",
    "criterion = RMSE()\n",
    "# criterion = WeightedRoll_MSE() #WARNING! RAM EXPLOSION HERE\n",
    "    \n",
    "torch.manual_seed(777)\n",
    "model = M5Transformer(d_input, d_model, d_output, q, v, h, N_e, N_d, n_months, attention_size=attention_size,\n",
    "                  dropout=dropout, chunk_mode=chunk_mode, pe=pe, n_lag_convs=n_lag_convs, e_days=e_days,\n",
    "                     d_days=d_days).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "                                            optimizer, 40, T_mult=2, \n",
    "                                            eta_min=lr/1e3, last_epoch=-1)\n",
    "\n",
    "model_name = \"seq2seq_v_final_idgaf_anymore.pth\"\n",
    "\n",
    "def save(m, fname, dirname='/home/timetraveller/Work/M5Models'):\n",
    "    with open(os.path.join(dirname, fname), 'wb') as handle:\n",
    "        pickle.dump(m, handle)\n",
    "        \n",
    "def zero_percentage(q):\n",
    "    l = len(q)\n",
    "    q = np.array(q)\n",
    "    return sum(q<1)/l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Re-Initialize scheduler and optimizer.\n",
      "WARNING! Re-Initialize scheduler and optimizer.\n",
      "WARNING! Re-Initialize scheduler and optimizer.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Re-Initialize scheduler and optimizer.\n",
      "WARNING! Re-Initialize scheduler and optimizer.\n",
      "WARNING! Re-Initialize scheduler and optimizer.\n"
     ]
    }
   ],
   "source": [
    "print(\"WARNING! Re-Initialize scheduler and optimizer.\")\n",
    "print(\"WARNING! Re-Initialize scheduler and optimizer.\")\n",
    "print(\"WARNING! Re-Initialize scheduler and optimizer.\")\n",
    "lrs = []\n",
    "for epoch in range(epochs):\n",
    "    for idx in range(len(train_loader)):\n",
    "        lr = scheduler.get_lr()\n",
    "        scheduler.step(epoch + idx/len(train_loader))\n",
    "        lrs.append(lr)\n",
    "plt.plot(lrs)\n",
    "plt.show()\n",
    "print(\"WARNING! Re-Initialize scheduler and optimizer.\")\n",
    "print(\"WARNING! Re-Initialize scheduler and optimizer.\")\n",
    "print(\"WARNING! Re-Initialize scheduler and optimizer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef33b7a65edb4646b0ca98974e58e55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26be6ecfc7d5424a83570e53c93c0cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=33349), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 0 | Loss: 2.1170 | RMSE: 2.1170\n",
      "[Valid] Epoch: 0 | Loss: 1.9790 | RMSE: 2.2025 | zc: (0.681/0.544) | wrmsse: 1.0331\n",
      "[1.1579182  0.15811094 0.08002508 0.2553747  0.1706825  0.18878523\n",
      " 0.21044599 0.24284018 0.2761703  0.31034526 0.34482764 0.37931035]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b70f554275f47e9bcf503802af21059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=33349), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 1 | Loss: 2.0031 | RMSE: 2.0031\n",
      "[Valid] Epoch: 1 | Loss: 2.0021 | RMSE: 2.2500 | zc: (0.662/0.544) | wrmsse: 0.7804\n",
      "[0.48888717 0.09106346 0.07473335 0.18044752 0.15540609 0.18143039\n",
      " 0.20896878 0.24231911 0.2760761  0.31034526 0.34482764 0.37931035]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83d1d96843e45ec86a36f93269c1f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=33349), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 2 | Loss: 1.9548 | RMSE: 1.9548\n",
      "[Valid] Epoch: 2 | Loss: 2.0199 | RMSE: 2.2830 | zc: (0.667/0.544) | wrmsse: 0.7977\n",
      "[0.4578484  0.08861425 0.07512995 0.17143718 0.15516279 0.18067031\n",
      " 0.20897416 0.24229652 0.27608553 0.31034528 0.34482764 0.37931035]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c51651528c04e5f8f1301ff1d6c8b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=33349), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 3 | Loss: 1.9197 | RMSE: 1.9197\n",
      "[Valid] Epoch: 3 | Loss: 2.0032 | RMSE: 2.2530 | zc: (0.683/0.544) | wrmsse: 0.9211\n",
      "[0.90910136 0.13283928 0.07782965 0.23260129 0.16412324 0.18642994\n",
      " 0.20983462 0.24266129 0.27612803 0.31034525 0.34482764 0.37931035]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1422df74284396892c3191b722dba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=33349), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 4 | Loss: 1.8940 | RMSE: 1.8940\n",
      "[Valid] Epoch: 4 | Loss: 2.0186 | RMSE: 2.2806 | zc: (0.667/0.544) | wrmsse: 0.7959\n",
      "[0.54420638 0.09642776 0.07504975 0.19241398 0.15696328 0.18258707\n",
      " 0.20912265 0.24240243 0.27608374 0.31034529 0.34482765 0.37931035]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9838dfeffb524059a5993e1865008d7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=33349), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 5 | Loss: 1.8721 | RMSE: 1.8721\n",
      "[Valid] Epoch: 5 | Loss: 2.0176 | RMSE: 2.2865 | zc: (0.669/0.544) | wrmsse: 0.7466\n",
      "[0.41129691 0.08698823 0.07419389 0.16503502 0.15238094 0.18024745\n",
      " 0.20875739 0.24218335 0.27605427 0.31034525 0.34482764 0.37931035]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a720a938cc4f7685ad99be62e217f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=33349), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 6 | Loss: 1.8532 | RMSE: 1.8532\n",
      "[Valid] Epoch: 6 | Loss: 2.0310 | RMSE: 2.3069 | zc: (0.642/0.544) | wrmsse: 0.7357\n",
      "[0.29413998 0.07232341 0.07310855 0.1657262  0.15346628 0.17991379\n",
      " 0.20875502 0.24217743 0.27605491 0.31034527 0.34482765 0.37931035]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b6773541d44e12a3a3a3efef8183f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=33349), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 7 | Loss: 1.8354 | RMSE: 1.8354\n",
      "[Valid] Epoch: 7 | Loss: 2.0021 | RMSE: 2.2508 | zc: (0.668/0.544) | wrmsse: 0.7919\n",
      "[0.53524945 0.09749397 0.07490881 0.18712834 0.15542768 0.18212665\n",
      " 0.20899464 0.24232787 0.27606932 0.31034526 0.34482764 0.37931035]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a43f3a9a57364cacbdbb136871b1e95f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=33349), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 8 | Loss: 1.8204 | RMSE: 1.8204\n",
      "[Valid] Epoch: 8 | Loss: 1.9957 | RMSE: 2.2422 | zc: (0.662/0.544) | wrmsse: 0.7042\n",
      "[0.32209683 0.07582664 0.07323563 0.15563203 0.15049031 0.17891967\n",
      " 0.20849207 0.24207676 0.27603211 0.31034525 0.34482764 0.37931035]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d993a54abf4eee8cba94882bfdf7ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=33349), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 9 | Loss: 1.8077 | RMSE: 1.8077\n",
      "[Valid] Epoch: 9 | Loss: 2.0226 | RMSE: 2.2827 | zc: (0.660/0.544) | wrmsse: 0.7022\n",
      "[0.33683071 0.07418703 0.07332257 0.16066741 0.15008643 0.17919901\n",
      " 0.20839387 0.24213601 0.27602875 0.31034529 0.34482765 0.37931035]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72fd3a9c9ea5435891b4e47f4664049b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=33349), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 10 | Loss: 1.7957 | RMSE: 1.7957\n",
      "[Valid] Epoch: 10 | Loss: 2.0291 | RMSE: 2.2922 | zc: (0.652/0.544) | wrmsse: 0.6524\n",
      "[0.18550306 0.06244943 0.07238823 0.13240341 0.14782863 0.17688602\n",
      " 0.20825446 0.24194727 0.27602168 0.31034531 0.34482765 0.37931035]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cea528111884fba99969b857f586c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=33349), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 11 | Loss: 1.7848 | RMSE: 1.7848\n",
      "[Valid] Epoch: 11 | Loss: 2.0225 | RMSE: 2.2830 | zc: (0.663/0.544) | wrmsse: 0.6959\n",
      "[0.30637245 0.07180109 0.07326256 0.14690618 0.14872393 0.17789609\n",
      " 0.20828339 0.24203771 0.27602591 0.31034528 0.34482764 0.37931035]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9669d8f08c9f40708cc798a01c089067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=33349), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 12 | Loss: 1.7743 | RMSE: 1.7743\n",
      "[Valid] Epoch: 12 | Loss: 2.0092 | RMSE: 2.2569 | zc: (0.695/0.544) | wrmsse: 0.9408\n",
      "[0.94366666 0.13275804 0.07811376 0.22634198 0.16262355 0.18546264\n",
      " 0.20958897 0.24263604 0.27611929 0.31034525 0.34482764 0.37931035]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10ebf84c3c44f58a3e1e7969adaf5be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=33349), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 13 | Loss: 1.7645 | RMSE: 1.7645\n",
      "[Valid] Epoch: 13 | Loss: 2.0284 | RMSE: 2.2969 | zc: (0.668/0.544) | wrmsse: 0.7246\n",
      "[0.38644668 0.07874638 0.07385492 0.1607814  0.15052237 0.17916846\n",
      " 0.20843449 0.24215371 0.27603731 0.31034528 0.34482765 0.37931035]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6ecc9bd116247e9bb9756d57495089e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=33349), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 14 | Loss: 1.7561 | RMSE: 1.7561\n",
      "[Valid] Epoch: 14 | Loss: 2.0321 | RMSE: 2.2937 | zc: (0.685/0.544) | wrmsse: 0.8798\n",
      "[0.77133101 0.11858176 0.07676905 0.20863756 0.15971302 0.1838062\n",
      " 0.20934928 0.24246237 0.27609419 0.31034526 0.34482764 0.37931035]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f147cb260f974e8fb6a2c0f4ffdf8d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=33349), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train] Epoch: 15 | Loss: 1.7477 | RMSE: 1.7477\n",
      "[Valid] Epoch: 15 | Loss: 2.0335 | RMSE: 2.3015 | zc: (0.658/0.544) | wrmsse: 0.6995\n",
      "[0.29977743 0.07272608 0.07294447 0.15700133 0.15042087 0.17900942\n",
      " 0.20847455 0.24208795 0.27603272 0.3103453  0.34482765 0.37931035]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111e1448be714b0b9a2bd6fd8540e49a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=33349), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-2e92fa04a6e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m#         loss = criterion(out, y, idx)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-8dc52bf2774d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mencoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_and_combine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_cont\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_lag\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#(bs, etime, d_inp)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mencoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e_inp_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_and_combine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_cont\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_lag\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#(bs, etime, d_inp-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_d_inp_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-8dc52bf2774d>\u001b[0m in \u001b[0;36membed_and_combine\u001b[0;34m(self, cont, cat, lag)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mcont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mlag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0mxcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mxcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_zc, val_zc = None, None\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_wrmsses = []\n",
    "val_wrmsses = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss, val_loss = 0, 0\n",
    "    train_rmse = 0\n",
    "    #Training phase\n",
    "    ypreds = [] \n",
    "    ytrue = []\n",
    "    bar = tqdm(train_loader)\n",
    "    for i, (x, idx, y) in enumerate(bar):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "#         loss = criterion(out, y, idx)   \n",
    "        loss = criterion(out, y)   \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step(epoch + i/len(train_loader))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            train_loss += loss.item()/len(train_loader)\n",
    "            ypreds = out.detach().cpu().numpy().flatten()\n",
    "            ytrue = y.cpu().numpy().flatten()\n",
    "            train_rmse += rmse_metric_npy(ypreds, ytrue)/len(train_loader)\n",
    "            bar.set_description(f\"{loss.item():.3f}\")\n",
    "    \n",
    "    train_wrmsse = 0.5 #whatever\n",
    "    print(f\"[Train] Epoch: {epoch} | Loss: {train_loss:.4f} | RMSE: {train_rmse:.4f}\")\n",
    "    \n",
    "    #Validation phase      \n",
    "    with torch.no_grad():\n",
    "                ytrue = []\n",
    "                ypreds = []\n",
    "\n",
    "                for i, (x, idx, y) in enumerate(val_loader):                \n",
    "                    out = model(x)\n",
    "#                     loss = criterion(out, y, idx)   \n",
    "                    loss = criterion(out, y)   \n",
    "                    val_loss += loss.item()/len(val_loader)\n",
    "                    ypreds += list(out.detach().cpu().numpy().flatten())\n",
    "                    ytrue += list(y.cpu().numpy().flatten())\n",
    "\n",
    "                rrmse = rmse_metric(ypreds, ytrue)\n",
    "                val_wrmsse, lws = wrmsse_metric(ypreds, ytrue, roll_mat_csr=roll_mat_csr, sw=sw, score_only=False)\n",
    "\n",
    "                if val_zc is None:\n",
    "                    val_zc = zero_percentage(ytrue) \n",
    "                zc = zero_percentage(ypreds)\n",
    "\n",
    "                print(f\"[Valid] Epoch: {epoch} | Loss: {val_loss:.4f} | RMSE: {rrmse:.4f} | zc: ({zc:.3f}/{val_zc:.3f}) | wrmsse: {val_wrmsse:.4f}\")\n",
    "                print(lws)\n",
    "\n",
    "    train_losses.append(train_loss)    \n",
    "    val_losses.append(val_loss)     \n",
    "    train_wrmsses.append(train_wrmsse)\n",
    "    val_wrmsses.append(val_wrmsse)\n",
    "    save(model, f\"{model_name}_{epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Train] Epoch: 0 | Loss: 2.7182 | RMSE: 2.9797 | zc: (0.640/0.563) | wrmsse: 0.5000\n",
    "# [Valid] Epoch: 0 | Loss: 2.3442 | RMSE: 2.8169 | zc: (0.684/0.544) | wrmsse: 1.3076\n",
    "# [2.10753578 0.25993714 0.08958656 0.45471797 0.21192379 0.20922057\n",
    "#  0.21467227 0.2447319  0.27654522 0.31034609 0.34482775 0.37931036]\n",
    "\n",
    "# 1.474: 100%\n",
    "# 239/239 [01:31<00:00, 2.60it/s]\n",
    "\n",
    "\n",
    "# [Train] Epoch: 1 | Loss: 2.4495 | RMSE: 2.6683 | zc: (0.659/0.563) | wrmsse: 0.5000\n",
    "# [Valid] Epoch: 1 | Loss: 2.2380 | RMSE: 2.6480 | zc: (0.606/0.544) | wrmsse: 1.0710\n",
    "# [0.95436476 0.14874324 0.07970559 0.26767532 0.18002803 0.191739\n",
    "#  0.21161642 0.24324118 0.2762905  0.31034575 0.34482771 0.37931036]\n",
    "\n",
    "# 1.565: 100%\n",
    "# 239/239 [06:18<00:00, 1.59s/it]\n",
    "\n",
    "\n",
    "# [Train] Epoch: 2 | Loss: 2.3338 | RMSE: 2.5162 | zc: (0.660/0.563) | wrmsse: 0.5000\n",
    "# [Valid] Epoch: 2 | Loss: 2.1796 | RMSE: 2.5528 | zc: (0.694/0.544) | wrmsse: 1.2141\n",
    "# [1.82708573 0.22902348 0.08625057 0.36194384 0.19074095 0.19988401\n",
    "#  0.21254641 0.24382938 0.27635083 0.3103456  0.34482769 0.37931036]\n",
    "\n",
    "# 1.582: 100%\n",
    "# 239/239 [01:39<00:00, 2.41it/s]\n",
    "\n",
    "\n",
    "# [Train] Epoch: 3 | Loss: 2.2453 | RMSE: 2.4197 | zc: (0.662/0.563) | wrmsse: 0.5000\n",
    "# [Valid] Epoch: 3 | Loss: 2.1339 | RMSE: 2.4776 | zc: (0.643/0.544) | wrmsse: 0.8956\n",
    "# [0.56030379 0.10468518 0.07631914 0.20161134 0.16246963 0.18462395\n",
    "#  0.20983267 0.24266924 0.27615998 0.31034544 0.34482767 0.37931036]\n",
    "\n",
    "# 1.370: 100%\n",
    "# 239/239 [03:04<00:00, 1.30it/s]\n",
    "\n",
    "\n",
    "# [Train] Epoch: 4 | Loss: 2.1952 | RMSE: 2.3458 | zc: (0.665/0.563) | wrmsse: 0.5000\n",
    "# [Valid] Epoch: 4 | Loss: 2.1111 | RMSE: 2.4347 | zc: (0.684/0.544) | wrmsse: 1.0589\n",
    "# [1.18325934 0.162551   0.08152355 0.26652444 0.17225429 0.19027757\n",
    "#  0.21067981 0.24313821 0.27622338 0.31034541 0.34482767 0.37931035]\n",
    "\n",
    "# 1.974: 100%\n",
    "# 239/239 [01:28<00:00, 2.71it/s]\n",
    "\n",
    "\n",
    "# [Train] Epoch: 5 | Loss: 2.1581 | RMSE: 2.3025 | zc: (0.663/0.563) | wrmsse: 0.5000\n",
    "# [Valid] Epoch: 5 | Loss: 2.0924 | RMSE: 2.4039 | zc: (0.662/0.544) | wrmsse: 0.9011\n",
    "# [0.6532173  0.11190976 0.0772809  0.21625822 0.16256436 0.18559452\n",
    "#  0.20978355 0.2427701  0.27616014 0.31034542 0.34482767 0.37931035]\n",
    "\n",
    "# 1.957: 92%\n",
    "# 219/239 [00:56<00:04, 4.01it/s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xd8lFXa//HPlQ4kIYEUAiEEkBaKlIg0ASsI9rK2te9iX3XdZ1fd3d8+z1Z/P90Vn9UVLNhQrGBXRAUBpRhq6FVCCSQQILSQdv3+OBMIIUBCJpnJzPV+vfJKZuaemWsg+Z5zn/vc5xZVxRhjTPAI8XUBxhhjGpYFvzHGBBkLfmOMCTIW/MYYE2Qs+I0xJshY8BtjTJCx4DfGmCBjwW+MMUHGgt8YY4JMmK8LqE5CQoKmp6f7ugxjjGk0FixYsFNVE2uyrV8Gf3p6OllZWb4uwxhjGg0R2VTTbW2oxxhjgowFvzHGBBkLfmOMCTIW/MYYE2Qs+I0xJshY8BtjTJCx4DfGmCATMMFfVFLGCzPX8/26nb4uxRhj/FrABH94aAgvzNzIm/NqfA6DMcYEpYAJ/tAQ4eIerfh2VR4Hi0t9XY4xxvitgAl+gFE9UygqKefbVXm+LsUYY/xWQAV///YtSIiO5PPsXF+XYowxfiuggj80RBjZI9mGe4wx5iQCKvjh6HDP9FX5vi7FGGP80imDX0Taish0EVkhIstF5MFqtukqInNE5LCI/KbKYyNFZLWIrBORR71ZfHXObt+ShOgIPsveVt9vZYwxjVJNevylwCOqmgEMAO4TkYwq2xQAvwKeqnyniIQCzwEXAxnADdU816vccI/N7jHGmBM5ZfCraq6qLvT8vA9YCbSpsk2eqv4IlFR5en9gnapuUNVi4G3gcq9UfhI23GOMMSdWqzF+EUkH+gDzaviUNsDmSre3UKXRqPTaY0QkS0Sy8vPrFtgVwz02u8cYY45X4+AXkWjgA+AhVS30diGq+oKqZqpqZmJijS4beUKhIcKI7jbcY4wx1alR8ItIOC7031TVybV4/a1A20q3Uz331bvRvVI4VFJmwz3GGFNFTWb1CPAysFJV/1XL1/8R6CQi7UUkArge+Lj2ZdaeDfcYY0z1wmqwzWDgZiBbRBZ77nscSANQ1XEi0grIAmKBchF5CMhQ1UIRuR+YCoQCE1R1ubc/RHUqhnsmL9zKoeIymkSENsTbGmOM3ztl8KvqbEBOsc123DBOdY99Dnx+WtXV0eieKbw5L4fpq/MY1TPFFyUYY4zfCbgzdyvr374FLZtF8JkN9xhjzBEBHfxhoSHuZK6VeRwqLvN1OcYY4xcCOvjBDfccKilj+mpbqtkYYyAIgt+Ge4wx5lgBH/xhoSGMsOEeY4w5IuCDH+ASz3DPDBvuMcaY4Aj+iuGeT224xxhjgiP4bbjHGGOOCorgh6Oze2y4xxgT7IIm+M9u34IWNrvHGGOCJ/iPnMy1yoZ7jDHBLWiCH9xwz8FiG+4xxgS3oAp+G+4xxpggC/6w0JAjV+YqKrHhHmNMcAqq4Acb7jHGmKAL/gEd3HDPp0ttuMcYE5yCLvhtuMcYE+xqcs3dtiIyXURWiMhyEXmwmm1ERP5XRNaJyFIR6VvpsTIRWez5apDr7Z6KDfcYY4JZTXr8pcAjqpoBDADuE5GMKttcDHTyfI0Bnq/02CFV7e35uswbRddVxXDPZ9nbfV2KMcY0uFMGv6rmqupCz8/7gJVAmyqbXQ68rs5cIE5E/PYit264J5lvVu6w4R5jTNCp1Ri/iKQDfYB5VR5qA2yudHsLRxuHKBHJEpG5InLFadbpdaN7trbhHmNMUKpx8ItINPAB8JCqFtbiPdqpaiZwIzBWRDqe4PXHeBqIrPz8/Fq8/Omx4R5jTLCqUfCLSDgu9N9U1cnVbLIVaFvpdqrnPlS14vsGYAZuj+E4qvqCqmaqamZiYmKNP8DpsuEeY0ywqsmsHgFeBlaq6r9OsNnHwC2e2T0DgL2qmisi8SIS6XmdBGAwsMJLtdfZqCOze+p/D8MYY/xFWA22GQzcDGSLyGLPfY8DaQCqOg74HBgFrAMOArd7tusGjBeRclwj84Sq+k3wD+zQkvim4XyencvIHq18XY4xxjSIUwa/qs4G5BTbKHBfNff/APQ87erqWcVSzR8t3kZRSRlR4aG+LskYY+pd0J25W5UN9xhjgk3QB3/l4R5jjAkGQR/8FWv32OweY0ywqMnB3YA3ulcKb/+4me/W5DOiux3kNcbUwOH9cLgQSg5BaZH7Xvnnar8fhJIiKD1U5btnm8gYuOXDei/dgp+jwz2fLc214Pd3+Wtg8zzodgk0ifd1NSYQHd4P+7bD/u3u+75cz/ftx95fvL/2rx0aAeFNIKwJhEcd+z0qFpolef/zVMOCn6PDPZ8ssdk9fqkwF5a9D9nvQe4Sd9/M/wfXvgZt+p78ueZYB3ZC3grYuQaaJUJSd2jRHkKC4He++KAnxCsHuefn/TuO/lxdoIc1gZhWEJMCrXpCp4sgOhmimrsgP1GYH/M9ym/+nS34PUb1tOEev1K0F1Z8DNnvwsZZgELrPjDiH5DQGT55ECaMgBF/h7N+AXLSGcfBp2gv5K1yIZ+38uj3gzuP3zYsChK7uEYgqRskZ0BShgu5QPh33ZMDM5+CxW9Ceemxjx0J9FbHBnpMytH7Y1pBZGxg/Ft4WPB7DOzYkjjP7B4Lfh8pPQxrv4Kl78KaqVB2GOLbw7DfQs9rIaHT0W3vngWTx8Dnv4GcOXDpM258NNiUHIL81ceGe95KKNxydJuIaEjsCl0udoGe1M39Wx7Ihx0rPM9bAeu/hSVvHX1eVJzbvqIhqHhuk7iG/5ynY+9WmPVPWPi6C+2+t0DbARDjCfaKHnsABXpNWfB7hIeGMNKGexpeeTls+t717Fd85HqqzRKh323Q62fQpl/1f5hNW8CN78Lsf8H0v0HuUvjZ6y6kAlFZCexad2y4562Ago2Aum1CIyGxM7Qb5AK6Iqibt4WQaibwNU91e1GVHSxwr1u5QVj6rjuIWSE29dg9g6QMt8cQFllvH79WCnPd78WCV0EV+t4M5zziPq8BQNxJt/4lMzNTs7KyGvx9Z67J55YJ8xl/cz/r9dcnVdixzAXKsg+gcCuEN3MHbHv+DDoMh9Ba9Ek2zoT374TD++CSp6H3DfVVecMrK3W91ln/dHtAABIKLTseG+5JGW7vqDb/bjWlCnu3eBqE5UcbnfzVUF5ytKbWfdyeWfcrXa+6oe3bAbOfhqwJoGXQ+yYY+huIS2v4WnxARBZ4VkI+9bYW/EeVlJVz1t++ZljnRJ65vtpFROtm83zXu824HFp08P7r+7vdm9wB2uz3IH8VhITBGRe4sOgyCiKanv5r79vuwn/TbOhzM4x60h1wa8wKNsKUu9wspu5Xun+jpG7QspM7WOhrZSWwaz3kLXcNwtqvYHs2SAi0H+b+X7td4oZT6tP+PPj+GfjxZSgrdg3/0P+C+PT6fV8/Y8FfB797fymfZeeS9YcLvDPcowrrvnG7npu+99wp7o944L3QbrB/jDGWlcKaL2Hha+5gWGiE23UPizr6c2iEux0W4YYVwjxfoZEnvi8sCvZuhqXvwea57r3aDoBe10LGldCspXc/w4y/u95xck/42WuuZ9zYqMKSt+Hz/3Ihesm/oOc1vq6qZvJWHZ2Btfsn93vQeYRrBDpd5N0G68Au+OEZmP+imwff6zoX+I3x/9wLLPjr4Ls1+dw6YT4v3NyPi+oy3FNeBis+dLue27Mhtg0MvN/9ESx+y+2OHiqAVr1g4H3Q/SoXlA1t71YX9gtfd9PZYtu4KZJlJe5ga+lhN8RQWuz5XlTp52J3W2twxnNiV/fH3/NaiG9Xv59pzVcwZYxrCK54zu1hNRaHdsOnv4blkyFtEFw1vnEOVajC1gWuAVj2gTuQHBkL3S5zjVj7oac/tfFgAfzwb5g33p0Q1fNaGPY7SDjDu5+hkbHgr4OK4Z7hnRMZezrDPSVFsGSS2/XcvdHtlg95yI1dVw724oOw9B2Y+zzsXA3RraD/L6DfHd7tBVenvNzN4MiaAGu+cH+kZ1wAmXe4Xlltx4nLyyo1EBWNRfHRnyOj3RTMhtyz2ZMD793mwmfAvXDB//imYa2Nn2bD5LvcCULDH4MhD/vNvO86KSuFn2a6vb6Vn0DxPjejpvtVbs+vdd+a/W4c2g1znoO549xc+x5XucBP7FL/n6ERsOCvo9Ma7ikqhAWvuF/M/Tvcga4hv4auo0/+x1sxFDT3P7D+Gzc0cub1Lqy8/Qu9Pw8WTXR17slxs2f63Az9bg3M8dDSYvjqDzB/PKSeBde+6p8zO0qL3RDV7LHu2M/VL7rZTIGo5JCbqpv9njsmUFbsPnPPa6HHNW5WUlWH9rgO0tz/uNlFGVfA8Efd8Q5zhAV/HdVquGd/PswbBz++6KYith8G5/zafa9tDzdvpfsFX/qOG0I54wIYcA90PP/0e8uqrieZNcH1tspLIP0c17vveon/94K9YfkU+OgBCA2Hq16EThf4uqKjdq6FD34BuYvdPPMR/3B7SMHg0B73O7nsfTczS8sh5UzPzKCr3HkZ88bBnGfd31a3S2HYo9Cqh68r90sW/HVUo+Ge3ZvcOOOiN9xwRrdL3ZCON3pqB3ZC1iuuMdm/w42PD7jHHbyq6UyVgwXuAGHWBNi11p2M0/smNz++ul5VoNu5Dt69xU1DHPobN5Tiy2EUVXds5cvH3MHwy/7tfoeC1b7troHOfs8NzyEQ0cwN6XQZ7Xr4Kb18XaVfs+D3gt++v4TPs7cfP9yzYwV8Pxay33czLs68DgY/dOxZpd5SehiWTYa5z7kDxE1bup76Wb+sfp60KmzJcmG/fLLba0jt757T/YrGP72xrooPupkyiye6g4tXvwzRDbMo1jEO7IKPH4DVn7lzFq4YB7EpDV+Hv9q13h0Q3r3JHfeqepKZqZZXg19E2gKvA8m4UwRfUNVnqmwjwDO46+4eBG5T1YWex24F/uDZ9K+q+tqpivKH4K8Y7nnxlkwuzEh2c/Bn/csdDA1v5nrOA++D5m3qv5iK4Zq5/4HVX7j57z2vcccBUnq5E5eWvuv2EnZku1P0e10Hmbe79UfMsRZNhM8ecXtB10yA9MEN997rvoEP73EHKi/4bzj7nurPqjWmlrwd/ClAiqouFJEYYAFwReWLpovIKOABXPCfDTyjqmeLSAsgC8jENRoLgH6quvtk7+kPwV9SVs5Zf53GXW02ck/ox24OfpN4OPtu6D/GLRngC7vWu3HPRW9CyQE3I2LnGrdL3KonZN7pGoVgXLemNrYvc0M/u3+C8/8Igx6s3wAuKYJv/sc13old4eqXrFE2XlWvQz0i8hHwrKpOq3TfeGCGqk7y3F4NDK/4UtW7qtvuRPwh+NmezeY37qbtgWUUNW1F1DkPutkvEc18W1eFQ7vd3Pul77kDYpl3uPn3/nAyWGNRVOiGXFZ86IbRkjJcKCd1c1+JXb3TwO9Y4Q7g5i13nYYL/2zDbsbrahP8tZqwLSLpQB9gXpWH2gCbK93e4rnvRPf7r6JCmPEPmDeO1CYtGNvkft44OIgPu5xL27osKeBtTeJh8IPuy5yeqFg3xTP7fTfPPG+lOyBevO/oNtGtjjYESd0gsRskda3ZHpWqO8lo2v9x73Xje9D5onr7OMbUVI2DX0SigQ+Ah1S18FTb15aIjAHGAKSl+eBMRVU3q2Dq426GQebtyHl/5MpDkUz492zuemMBk+8dZKt2BhoRdxJRr2vd7SMLkq2E/JVHV8LMesVdJq9C87ZVGoNu7ryLip78vh3w0b2w7mvoPBIuexaiExv+8xlTjRoFv4iE40L/TVWdXM0mW4G2lW6neu7bihvuqXz/jOreQ1VfAF4AN9RTk7q8Zuc6t677hulu2OS6NyHVTcts1xTGXt+bO17N4vdTlvHUtb0QG04JXCIQ19Z9Ve6dl5fBnk2VlkRe6Raa2zDDnYTknuyuZpXYza1LVHwARv/THXex3xnjR04Z/J4ZOy8DK1X1XyfY7GPgfhF5G3dwd6+q5orIVODvIlJxcdSLgMe8ULd3lBxyM3W+H+vOmL34STjrzuPmd5/XNZmHLujE2K/X0jstjpsH1PNaM8b/hIS6M0xbdHBnY1coK4WCDZ5liitd8SqhC1w61pYTMH6pJj3+wcDNQLaILPbc9ziQBqCq44DPcTN61uGmc97ueaxARP4C/Oh53p9VtcB75dfB2mmul7/7J3em4EV/O+ka4r86rxNLt+zlz58sJyMlln7t7ELfBreuUWLn4DwpzjRawXcC194t7mzJlR+7BdRG/xM6DKvZUw+WcOmzszlcWsYnDwwhKcYP1kQ3xhhqN6sneM4cKSuB7/8Xnu3vFoc6749wz/c1Dn2A5k3DGX9zP/YeKuH+txZRUlZejwUbY0z9CI7g3zQHxg+FaX+E9ufAffPcei2ncY3QbimxPHFVL+ZvLOCJL1bVQ7HGGFO/Avti6wd2wrQ/ubVZmreF699yV76q4wyLK/q0YfHmPbw8eyNnto3jsjNbe6lgY4ypf4EZ/OXlbuXDr//bLWUw+CEY9luvnnX7+KhuLNu6l9+9v5QuyTF0aWVLJBhjGofAG+rJXQIvXwifPgTJPeDu7+HC//H6UgsRYSH856a+REeFcffEBRQWlXj19Y0xpr4ETvAXH4AvHoUXhrspmleOh9s+dafX15Ok2Cj+c1NfNhcc5NfvLKG83P9mSBljTFWBE/whYe46sv1uhwey3OULG+BsybPSW/D70d34euUO/jNjXb2/nzHG1FXgjPGHRcJd3/lk1cPbBqWzePMe/jltDT1T4xjW2dZkMcb4r8Dp8YPPlroVEf5xVU+6JMfw4NuL2Fxw0Cd1GGNMTQRW8PtQ04gwxv28H2Xlyl1vLKCopMzXJRljTLUs+L0oPaEZY6/rzYrcQn4/ZRn+uByGMcZY8HvZ+d2S+dX5nfhg4RYmzsvxdTnGGHMcC/568ND5nTi3SyJ//mQ5Czad9PLCxhjT4Cz460FIiDD2uj6kNG/CvW8uIH/fYV+XZIwxR1jw15PmTcMZ9/OKlTwXUmoreRpj/IQFfz3KaB3LP67qyTxbydMY40cs+OvZlX1SuXVgO16avZFPlmzzdTnGGGPB3xB+PzqDfu3i+d0HS1mzY5+vyzHGBLlTBr+ITBCRPBFZdoLH40VkiogsFZH5ItKj0mM/iUi2iCwWkXq6lqL/q1jJs1lkGHe9YQd7jTG+VZMe/6vAyJM8/jiwWFV7AbcAz1R5/FxV7V3Ta0EGquTYKJ6/qS/b9xZx7bgfbFkHY4zPnDL4VXUmUHCSTTKAbz3brgLSRSTZO+UFlsz0Fkz8xdkUHCjmmnE/2LCPMcYnvDHGvwS4CkBE+gPtgFTPYwp8JSILRGSMF96r0evXLp537x6IKvxs/BwW5dgJXsaYhuWN4H8CiBORxcADwCKgYoWyIaraF7gYuE9Ehp7oRURkjIhkiUhWfn6+F8ryX11bxfL+3YOIjQrnppfmMWttYH9eY4x/qXPwq2qhqt6uqr1xY/yJwAbPY1s93/OAKUD/k7zOC6qaqaqZiYmBv559WsumvH/3QNJaNOWOV3/k8+xcX5dkjAkSdQ5+EYkTkQjPzV8AM1W1UESaiUiMZ5tmwEVAtTODglVSbBTvjBlIr9Q47n9rIZPm26Juxpj6d8orcInIJGA4kCAiW4A/AeEAqjoO6Aa8JiIKLAfu9Dw1GZgi7vKHYcBbqvqltz9AY9e8aThv3NmfeyYu5LHJ2ew5WMI9wzv6uixjTAATf1wzPjMzU7Oygmvaf3FpOY+8t4RPlmzjrmEdeHRkV6QBrhlsjAkMIrKgptPmA+eau41cRFgIY6/rTfMmYYz/bgN7D5bwtyt7Ehpi4W+M8S4Lfj8SGiL85fIexDeN4N/frmPvoRLGXt+byLBQX5dmjAkgtlaPnxERHrmoC3+8JIMvlm3nzlezOHC41NdlGWMCiAW/n7pzSHueuvZM5mzYxY0vzWP3gWJfl2SMCRAW/H7smn6pjPt5P1bmFvKz8XPYvrfI1yUZYwKABb+fuzAjmddu70/u3iKufv4HNu484OuSjDGNnAV/IzCwY0sm/XIAh0rKuHbcDyzfttfXJRljGjEL/kaiZ2pz3r1rIBGhIVw/fi7zN55swVRjjDkxC/5G5IykaN67ZxCJsZHc/PI8vl21w9clGWMaIQv+RqZNXBPeu2sgnZNj+OXrC/hw0VZfl2SMaWQs+BuhltGRvPXLs+mf3oKH3lnMU1NXU1xa7uuyjDGNhAV/IxUTFc4rt5/Ftf1SeXb6Oi5/7ntW5hb6uixjTCNgwd+IRYWH8uS1Z/LSLZnk7zvMZc/O5rnp6ygts96/MebELPgDwAUZyUx7eCgjurfiyamruWbcHNbn7/d1WcYYP2XBHyDim0Xw7I19+fcNffhp1wFGPTOLCbM3Ul7uf8tuG2N8y4I/wFx6Zmu+engoQ85I4M+fruCGF+eyueCgr8syxvgRC/4AlBQTxUu3ZvLkNb1Ysa2QkWNnMml+Dv540R1jTMOz4A9QIsK1mW358uGh9E6L47HJ2dz2yo+20Jsx5tTBLyITRCRPRKq9ULqIxIvIFBFZKiLzRaRHpcdGishqEVknIo96s3BTM23imvDGHWfz58u7M39jARc9/R0fLtpqvX9jglhNevyvAiNP8vjjwGJV7QXcAjwDICKhwHPAxUAGcIOIZNSpWnNaQkKEWwam8/mD59ApOYaH3lnMPRMXsnP/YV+XZozxgVMGv6rOBE62IlgG8K1n21VAuogkA/2Bdaq6QVWLgbeBy+tesjld7ROa8e5dA3l8VFe+XZXHiKdn8uWyXF+XZYxpYN4Y418CXAUgIv2BdkAq0AbYXGm7LZ77qiUiY0QkS0Sy8vPzvVCWqU5oiDBmaEc+/dUQUuKiuHviQh5+ZzF7D5b4ujRjTAPxRvA/AcSJyGLgAWARUFbbF1HVF1Q1U1UzExMTvVCWOZnOyTFMuXcwD13QiU+WbOOisd8xY3Wer8syxjSAOge/qhaq6u2q2hs3xp8IbAC2Am0rbZrquc/4ifDQEB66oDNT7h1M8ybh3PbKjzw2OZv9dnF3YwJanYNfROJEJMJz8xfATFUtBH4EOolIe8/j1wMf1/X9jPf1TG3Ox/cP4a5hHXj7xxwu+KfN/DEmkNVkOuckYA7QRUS2iMidInK3iNzt2aQbsExEVuNm8DwIoKqlwP3AVGAl8K6qLq+PD2HqLio8lMcu7sYH9wwiKTaSh95ZzFXP/8DizXt8XZoxxsvEH3t1mZmZmpWV5esyglZ5uTJ50Vb+75eryN93mKv7pvLbkV1Ijo3ydWnGmBMQkQWqmlmTbe3MXXOckBDhmn6pTP/NcO4Z3pFPlmzj3Kdm8Nz0dRSV1Pq4vTHGz1jwmxOKjgzjdyO7Mu3XQzmnUwJPTl3NhU9/x5fLcm3835hGzILfnFK7ls0Yf3Mmb/7ibJqGh3H3xIXc+OI8u+KXMY2UBb+pscFnJPDZr4bwl8u7s3J7IaP/dxa/n5LNLlv6wZhGxYLf1EpYaAg3D0xnxm+Gc8vAdN7+cTPDn5rBy7M3UmKXfDSmUbDgN6clrmkE/31Zd7588Bx6t43jL5+uYOTYmUy3s3+N8XsW/KZOOiXH8Pod/Xn51kzKypXbX/mR21+Zb9f8NcaPWfCbOhMRzu+WzFcPD+PxUV3J+mk3I56eyV8+XcHeQ7b4mzH+xoLfeE1EWAhjhnbk298M55p+qUz4fiPnPjWDiXM3UVxq4//G+AsLfuN1iTGRPHF1Lz65fwhnJEbzhw+Xcd4/Z/D2/BxrAIzxAxb8pt70aNOcd+4awCu3nUXLZhE8Ojmbc5+awSRrAIzxKVurxzQIVWXGmnzGfr2WJZv30CauCfefdwZX900lIsz6H8bUVW3W6rHgNw3KGgBj6ocFv/F7qsp3ngZgsacBuO/cM7imnzUAxpwOC37TaFgDYIx3WPCbRscaAGPqxoLfNFqqysy1O3l62hprAIypBa9eiEVEJohInogsO8HjzUXkExFZIiLLReT2So+Vichiz5ddb9eckogwrHMiU+4dxGt39CcpNpLHp7hpoG/OsxPBjPGGU/b4RWQosB94XVV7VPP440BzVf2diCQCq4FWqlosIvtVNbq2RVmP31RQVWat3cnTX69hUY7bA7hneEeuzUwlMizU1+UZ4ze82uNX1ZlAwck2AWJERIBoz7alNXlzY05FRBjaOZHJ9wzidc8ewB8+XMY5/3c6479bz74iWwvImNryxqDps0A3YBuQDTyoqhX741EikiUic0XkCi+8lwlSlRuAiXeeTefkGP7xxSoGPfEtT05dxU67GIwxNRbmhdcYASwGzgM6AtNEZJaqFgLtVHWriHQAvhWRbFVdX92LiMgYYAxAWlqaF8oygUhEGNIpgSGdEli6ZQ/jvlvPf2as56VZG/lZZlvGDO1A2xZNfV2mMX6tRrN6RCQd+PQEY/yfAU+o6izP7W+BR1V1fpXtXvW8xvunej8b4ze1sSF/Py/M3MAHC7dQrnBJrxTuHtaRbimxvi7NmAbj1TH+GsgBzve8cTLQBdggIvEiEum5PwEYDKzwwvsZc4wOidE8cXUvZv32PO4c0p6vV+zg4mdmcfsr85m/sQB/nLJsjC/VZFbPJGA4kADsAP4EhAOo6jgRaQ28CqQAguv9TxSRQcB4oBzXwIxV1ZdrUpT1+E1d7D1YwsR5m5gweyO7DhTTNy2Oe4afwfldkwgJEV+XZ0y9sBO4jAGKSsp4L2sz42duYMvuQ3RKiubuYR25rHdrwkPtZDATWCz4jamktKycz7JzeX7GelZt30fr5lH8cmgHrjurLU0jvDG/wRjfs+A3phqqyozV+Tw/Yz3zfyogvmk4tw1qzy0D2xHfLMLX5RlTJxb8xpzCgk0FPD9jA1+v3EGT8FCu7teGG/qn0b11c1+XZsxpseA3pobW7NjH+O828OnSbRwuLefM1OZc3z+NS89sTXSkDQOZxsOC35ha2nuwhCmLtjBp/mZW79hHs4hQLuvdhhv7p9Ez1fa2VRHoAAAOAUlEQVQCjP+z4DfmNKkqizbvYdK8HD5Zuo2iknK6t47lhv5pXN67NTFR4b4u0ZhqWfAb4wWFRSV8tHgbk+blsCK3kCbhoVx6Zgo39E+jd9s43LqExvgHC35jvEhVyd66l0nzc/ho8TYOFpfRtVUMN/RP44o+bWjexPYCjO9Z8BtTT/YfLuXjxdt4+8cclm7ZS1R4CKN6pnBj/zT6tYu3vQDjMxb8xjSAZZX2AvYfLqVTUjTX90/j6r5tiGtq5wWYhmXBb0wDOlhcyqdLcnlrfg6LN+8hIiyEEd1bMbpnCsO7JBIVblcKM/XPgt8YH1mZW8jb83P4ZGkuBQeKaRYRyvndkhlljYCpZxb8xvhYaVk5czcU8Fl2Ll8uy2X3wZIjjcDoXikM62yNgPEuC35j/MjRRmAbXy7bbo2AqRcW/Mb4qdKycuZs2MXn2bnHNAIXZLjhIGsEzOmy4DemESgpK2dulUYgOjKM87slWSNgas2C35hGpqIR+GxpLlOXH9sIjO6ZwlBrBMwpWPAb04iVlJUzZ73bE6hoBJpFhDK8axIjurfi3C6JtmaQOY7Xg19EJgCXAHmq2qOax5sDE4E0IAx4SlVf8Tx2K/AHz6Z/VdXXTvV+FvzGOBWNwBfLcpm2Ygc79xcTERrCoDNaMqJ7Ky7MSCYhOtLXZRo/UB/BPxTYD7x+guB/HGiuqr8TkURgNdAKiAaygExAgQVAP1XdfbL3s+A35nhl5crCnN1MXbadqSu2s7ngECKQ2S6eEd1bMaJ7K9q2aOrrMo2P1Cb4a3SlCVWdKSLpJ9sEiBG3UEk0UACUAiOAaapa4ClsGjASmFST9zXGHBUaIpyV3oKz0lvw+9HdWJm7j6nLtzN1+Xb++tlK/vrZSrqlxDKiezIjureia6sYWzvIVMtblxh6FvgY2AbEANeparmItAE2V9puC9DGS+9pTNASETJax5LROpaHL+xMzq6DRxqBZ75Zy9iv19KuZVMuynCNQN+0eEJCrBEwjreCfwSwGDgP6AhME5FZtXkBERkDjAFIS0vzUlnGBIe0lk355dAO/HJoB/L2FfH1ijymLt/Oqz/8xIuzNpIQHcmFGcmM6J7MoI4JRISF+Lpk40PeCv7bgSfUHTBYJyIbga7AVmB4pe1SgRnVvYCqvgC8AG6M30t1GRN0kmKiuPHsNG48O43CohKmr8rjq+U7+HjxVibNzyEmMoxzuyZxQUYyQzsl2EqiQchbwZ8DnA/MEpFkoAuwAVgH/F1E4j3bXQQ85qX3NMacQmxUOJf3bsPlvdtQVFLGD+t3MnXZDr5euYOPl2wjRKBPWjzndklkeJckureOteMCQaCms3om4XruCcAO4E9AOICqjhOR1sCrQAoguN7/RM9z7wAe97zU3yqmeZ6Mzeoxpn6VlStLt+xh+up8ZqzOY+mWvQAkxUQyvEsi53ZJYnCnBGLtfIFGw07gMsbUSv6+w3y3xjUCM9fkU1hUSliI0K9dPOd2TeLcLkl0To62vQE/ZsFvjDltpWXlLNq8h+mr8pi+Op+VuYUAtG4exXBPIzCoY0uaRXprpNh4gwW/McZrcvce4rvV+UxfncfstTs5UFxGRGgIZ3dowbDOiZzbNYkOCc1sb8DHLPiNMfWiuLScrJ8KmL7a7Q2sy9sPQFqLpgzvksjQTokM6NiSaNsbaHAW/MaYBrG54CAz1uQzfVUec9bv4lBJGeGhQt+0eIZ2TmRY50QyUmLt5LEGYMFvjGlwh0vLWPDTbr5bm8/MNTuPHBtIiI5gyBkJDO2cyJBOCSTFRPm40sBkwW+M8bm8fUXMWrOTWWvzmbV2J7sOFAPQLSWWoZ0TGNYpkX7p8USG2XUGvMGC3xjjV8rLlRW5hXy3Jp+Za/JZsGk3peVKk/BQBnZsydBOCZzTOdEOEteBBb8xxq/tP1zK3PW7mLnWNQQ/7ToIQJu4Jp5jAwkMOsNOIKsNC35jTKOSs+ug59hAPnPW72L/4VJCBHqmxjGwQ0sGdWxJZno8TSNsttCJWPAbYxqtkrJyFuXsYfbafOZs2MWinD2UlivhoULvtnEM7JjAwA4t6ZMWZ9chrsSC3xgTMA4cLiVr027mrN/FnPU7yd66l3KFyLAQMtPjGdihJQM7JtArtTnhocG73LQFvzEmYO09VML8jQXMWb+LH9bvZNX2fQA0iwjlrPYtGNSxJYM6JtAtJZbQIDp/wOuXXjTGGH/RvEk4F2Ykc2FGMgC79h9m3sYCfli/kx/W72LG6nwAYqPCGOA5PjCwY4ItMleJBb8xplFrGR3JqJ4pjOqZAsCOwqIjewNzNuziqxU7AHciWd+0ePq2i6dvWjy9UpsH7TECG+oxxgS0zQUHmbN+F3M37GJBzm42eaaOhoW46xb3TYunT1ocfdPiSY1v0mj3CmyM3xhjTmDn/sMsytnDwpzdLNy0m6Vb9nKopAyAxJhI+qbF0c+zV9CjTePZK7AxfmOMOYGKC89XHCMoLStn1fZ9RxqChTl7mLrcDQ+FhwoZrZvT17NH0LddPK2bRzXavYIK1uM3xpgq8vcdZlGOawQW5uxm6ZY9FJWUA5AcG+kagbR4+raLo3tr/9gr8GqPX0QmAJcAearao5rH/wu4qdLrdQMSVbVARH4C9gFlQGlNizLGGF9KjInkou6tuKh7K8CdVLYq1+0VLNi0m4U5u/li2XYAIkJDjhwr6NvO7Rm0jmviy/JP6ZQ9fhEZCuwHXq8u+KtseynwsKqe57n9E5CpqjtrU5T1+I0x/i5vX9GRYwWLNu1hyZY9HC51ewWtYqOONAJ90uLp3jq23vcKvNrjV9WZIpJew/e+AZhUw22NMabRSoqJYkT3VoyotFewMrfwyHGChTm7+TzbP/cKajTG7wn+T0/W4xeRpsAW4AxVLfDctxHYDSgwXlVfqElR1uM3xgSCvH1FLNy0x3O8wM0gOtFeQY82sXW6NoGvZvVcCnxfEfoeQ1R1q4gkAdNEZJWqzqzuySIyBhgDkJaW5sWyjDHGN5JiohjZoxUje7i9guJSz16B58Dxoip7Bb3bxvH2mAH1fqlKbwb/9VQZ5lHVrZ7veSIyBegPVBv8nr2BF8D1+L1YlzHG+IWIsBDObBvHmW3juH2wuy+vsOhII7D3UEmDXJ/YK8EvIs2BYcDPK93XDAhR1X2eny8C/uyN9zPGmECRFHvsXkFDqMl0zknAcCBBRLYAfwLCAVR1nGezK4GvVPVApacmA1M8JzqEAW+p6pfeK90YY8zpqMmsnhtqsM2rwKtV7tsAnHm6hRljjKkfwXvVAmOMCVIW/MYYE2Qs+I0xJshY8BtjTJCx4DfGmCBjwW+MMUHGL9fjF5F8YNNpPj0BqNVqoA3M3+sDq9Eb/L0+8P8a/b0+8K8a26lqYk029MvgrwsRyfLndf/9vT6wGr3B3+sD/6/R3+uDxlFjdWyoxxhjgowFvzHGBJlADP4arfnvQ/5eH1iN3uDv9YH/1+jv9UHjqPE4ATfGb4wx5uQCscdvjDHmJAIm+EVkpIisFpF1IvKor+upSkTaish0EVkhIstF5EFf11QdEQkVkUUi8qmva6mOiMSJyPsiskpEVorIQF/XVJWIPOz5P14mIpNEJMoPapogInkisqzSfS1EZJqIrPV8j/ez+p70/D8vFZEpIhLnq/pOVGOlxx4RERWRBF/UVlsBEfwiEgo8B1wMZAA3iEiGb6s6TinwiKpmAAOA+/ywRoAHgZW+LuIkngG+VNWuuGW//apWEWkD/ArI9FyjOhR3dTpfexUYWeW+R4FvVLUT8I3ntq+8yvH1TQN6qGovYA3wWEMXVcWrHF8jItIWd6GpnIYu6HQFRPDjLum4TlU3qGox8DZwuY9rOoaq5qrqQs/P+3CB1ca3VR1LRFKB0cBLvq6lOp4rvQ0FXgZQ1WJV3ePbqqoVBjQRkTCgKbDNx/XgudZ1QZW7Lwde8/z8GnBFgxZVSXX1qepXqlrquTkXSG3wwo6tp7p/Q4Cngd8CjeaAaaAEfxtgc6XbW/CzUK1MRNKBPsA831ZynLG4X+ByXxdyAu2BfOAVz3DUS57LevoNz3Wmn8L1/nKBvar6lW+rOqFkVc31/Lwdd9U8f3UH8IWvi6hKRC4HtqrqEl/XUhuBEvyNhohEAx8AD6lqoa/rqSAilwB5qrrA17WcRBjQF3heVfsAB/Dt8MRxPOPkl+MaqdZAMxH5+cmf5Xvqpvf5ZY9VRH6PGyp909e1VCYiTYHHgf/j61pqK1CCfyvQttLtVM99fkVEwnGh/6aqTvZ1PVUMBi4TkZ9wQ2XnichE35Z0nC3AFlWt2FN6H9cQ+JMLgI2qmq+qJcBkYJCPazqRHSKSAuD5nufjeo4jIrcBlwA3qf/NPe+Ia+CXeP5uUoGFItJwV00/TYES/D8CnUSkvYhE4A6mfezjmo4h7qrzLwMrVfVfvq6nKlV9TFVTVTUd9+/3rar6VU9VVbcDm0Wki+eu84EVPiypOjnAABFp6vk/Px8/OwBdycfArZ6fbwU+8mEtxxGRkbihx8tU9aCv66lKVbNVNUlV0z1/N1uAvp7fU78WEMHvOQB0PzAV90f2rqou921VxxkM3IzrSS/2fI3ydVGN0APAmyKyFOgN/N3H9RzDszfyPrAQyMb9jfn87E4RmQTMAbqIyBYRuRN4ArhQRNbi9lSe8LP6ngVigGmev5dxvqrvJDU2SnbmrjHGBJmA6PEbY4ypOQt+Y4wJMhb8xhgTZCz4jTEmyFjwG2NMkLHgN8aYIGPBb4wxQcaC3xhjgsz/B6+zx0gl1Z8vAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_wrmsses)\n",
    "plt.plot(val_wrmsses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dee6e9f96f4402d9b03002797c02b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Valid] Epoch: 16 | Loss: 2.0186 | RMSE: 2.2705 | zc: (0.663/0.544) | wrmsse: 0.6744\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "            ytrue = []\n",
    "            ypreds = []\n",
    "            \n",
    "            for i, (x, idx, y) in enumerate(tqdm(val_loader)):                \n",
    "                out = model(x)\n",
    "#                 loss = criterion(out, y, i)   \n",
    "                loss = criterion(out, y)   \n",
    "                val_loss += loss.item()/len(val_loader)\n",
    "                ypreds += list(out.detach().cpu().numpy().flatten())\n",
    "                ytrue += list(y.cpu().numpy().flatten())\n",
    "                \n",
    "            rrmse = rmse_metric(ypreds, ytrue)\n",
    "            val_wrmsse = wrmsse_metric(ypreds, ytrue, roll_mat_csr=roll_mat_csr, sw=sw)\n",
    "            \n",
    "            if val_zc is None:\n",
    "                val_zc = zero_percentage(ytrue) \n",
    "            zc = zero_percentage(ypreds)\n",
    "            \n",
    "            print(f\"[Valid] Epoch: {epoch} | Loss: {val_loss:.4f} | RMSE: {rrmse:.4f} | zc: ({zc:.3f}/{val_zc:.3f}) | wrmsse: {val_wrmsse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypreds = load('/home/timetraveller/Work/M5Models/whatever.tmp')\n",
    "ypreds = np.array(ypreds).reshape(NUM_ITEMS, -1)\n",
    "print(ypreds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv(\"/home/timetraveller/Desktop/kek.csv\")\n",
    "submission_df.iloc[:NUM_ITEMS, 1:] = ypreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"/home/timetraveller/Desktop/tch.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WRMSSE Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "df_train_full = pd.read_csv(\"../new_notebooks_phase2/sales_train_evaluation.csv\")\n",
    "df_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class WRMSSEEvaluator(object):\n",
    "\n",
    "    def __init__(self, train_df: pd.DataFrame, valid_df: pd.DataFrame, \n",
    "                 calendar: pd.DataFrame, prices: pd.DataFrame):\n",
    "        train_y = train_df.loc[:, train_df.columns.str.startswith('d_')]\n",
    "        train_target_columns = train_y.columns.tolist()\n",
    "        weight_columns = train_y.iloc[:, -28:].columns.tolist()\n",
    "\n",
    "        train_df['all_id'] = 'all'  # for lv1 aggregation\n",
    "\n",
    "        id_columns = train_df.loc[:, ~train_df.columns.str.startswith('d_')]\\\n",
    "                     .columns.tolist()\n",
    "        valid_target_columns = valid_df.loc[:, valid_df.columns.str.startswith('d_')]\\\n",
    "                               .columns.tolist()\n",
    "\n",
    "        if not all([c in valid_df.columns for c in id_columns]):\n",
    "            valid_df = pd.concat([train_df[id_columns], valid_df], \n",
    "                                 axis=1, sort=False)\n",
    "\n",
    "        self.train_df = train_df\n",
    "        self.valid_df = valid_df\n",
    "        self.calendar = calendar\n",
    "        self.prices = prices\n",
    "\n",
    "        self.weight_columns = weight_columns\n",
    "        self.id_columns = id_columns\n",
    "        self.valid_target_columns = valid_target_columns\n",
    "\n",
    "        weight_df = self.get_weight_df()\n",
    "\n",
    "        self.group_ids = (\n",
    "            'all_id',\n",
    "            'state_id',\n",
    "            'store_id',\n",
    "            'cat_id',\n",
    "            'dept_id',\n",
    "            ['state_id', 'cat_id'],\n",
    "            ['state_id', 'dept_id'],\n",
    "            ['store_id', 'cat_id'],\n",
    "            ['store_id', 'dept_id'],\n",
    "            'item_id',\n",
    "            ['item_id', 'state_id'],\n",
    "            ['item_id', 'store_id']\n",
    "        )\n",
    "\n",
    "        for i, group_id in enumerate(tqdm(self.group_ids)):\n",
    "            train_y = train_df.groupby(group_id)[train_target_columns].sum()\n",
    "            scale = []\n",
    "            for _, row in train_y.iterrows():\n",
    "                series = row.values[np.argmax(row.values != 0):]\n",
    "                scale.append(((series[1:] - series[:-1]) ** 2).mean())\n",
    "            setattr(self, f'lv{i + 1}_scale', np.array(scale))\n",
    "            setattr(self, f'lv{i + 1}_train_df', train_y)\n",
    "            setattr(self, f'lv{i + 1}_valid_df', valid_df.groupby(group_id)\\\n",
    "                    [valid_target_columns].sum())\n",
    "\n",
    "            lv_weight = weight_df.groupby(group_id)[weight_columns].sum().sum(axis=1)\n",
    "            setattr(self, f'lv{i + 1}_weight', lv_weight / lv_weight.sum())\n",
    "\n",
    "    def get_weight_df(self) -> pd.DataFrame:\n",
    "        day_to_week = self.calendar.set_index('d')['wm_yr_wk'].to_dict()\n",
    "        weight_df = self.train_df[['item_id', 'store_id'] + self.weight_columns]\\\n",
    "                    .set_index(['item_id', 'store_id'])\n",
    "        weight_df = weight_df.stack().reset_index()\\\n",
    "                   .rename(columns={'level_2': 'd', 0: 'value'})\n",
    "        weight_df['wm_yr_wk'] = weight_df['d'].map(day_to_week)\n",
    "\n",
    "        weight_df = weight_df.merge(self.prices, how='left',\n",
    "                                    on=['item_id', 'store_id', 'wm_yr_wk'])\n",
    "        weight_df['value'] = weight_df['value'] * weight_df['sell_price']\n",
    "        weight_df = weight_df.set_index(['item_id', 'store_id', 'd'])\\\n",
    "                    .unstack(level=2)['value']\\\n",
    "                    .loc[zip(self.train_df.item_id, self.train_df.store_id), :]\\\n",
    "                    .reset_index(drop=True)\n",
    "        weight_df = pd.concat([self.train_df[self.id_columns],\n",
    "                               weight_df], axis=1, sort=False)\n",
    "        return weight_df\n",
    "\n",
    "    def rmsse(self, valid_preds: pd.DataFrame, lv: int) -> pd.Series:\n",
    "        valid_y = getattr(self, f'lv{lv}_valid_df')\n",
    "        score = ((valid_y - valid_preds) ** 2).mean(axis=1)\n",
    "        scale = getattr(self, f'lv{lv}_scale')\n",
    "        return (score / scale).map(np.sqrt) \n",
    "\n",
    "    def score(self, valid_preds: Union[pd.DataFrame, \n",
    "                                       np.ndarray]) -> float:\n",
    "        assert self.valid_df[self.valid_target_columns].shape \\\n",
    "               == valid_preds.shape\n",
    "\n",
    "        if isinstance(valid_preds, np.ndarray):\n",
    "            valid_preds = pd.DataFrame(valid_preds, \n",
    "                                       columns=self.valid_target_columns)\n",
    "\n",
    "        valid_preds = pd.concat([self.valid_df[self.id_columns], \n",
    "                                 valid_preds], axis=1, sort=False)\n",
    "\n",
    "        all_scores = []\n",
    "        for i, group_id in enumerate(self.group_ids):\n",
    "\n",
    "            valid_preds_grp = valid_preds.groupby(group_id)[self.valid_target_columns].sum()\n",
    "            setattr(self, f'lv{i + 1}_valid_preds', valid_preds_grp)\n",
    "            \n",
    "            lv_scores = self.rmsse(valid_preds_grp, i + 1)\n",
    "            setattr(self, f'lv{i + 1}_scores', lv_scores)\n",
    "            \n",
    "            weight = getattr(self, f'lv{i + 1}_weight')\n",
    "            lv_scores = pd.concat([weight, lv_scores], axis=1, \n",
    "                                  sort=False).prod(axis=1)\n",
    "            \n",
    "            all_scores.append(lv_scores.sum())\n",
    "            \n",
    "        self.all_scores = all_scores\n",
    "\n",
    "        return np.mean(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/\"\n",
    "d_dtypes = {}\n",
    "for i in range(1914):\n",
    "    d_dtypes[f'd_{i}'] = np.int32\n",
    "    \n",
    "sales = pd.read_csv(DATA_DIR + 'sales_train_validation.csv',\n",
    "                    dtype=d_dtypes)\n",
    "\n",
    "# changing wide format to long format for model training\n",
    "d = ['d_' + str(i) for i in range(1802,1914)]\n",
    "sales_mlt = pd.melt(sales, id_vars=['item_id','dept_id','cat_id','store_id',\n",
    "                                    'state_id'], value_vars=d)\n",
    "sales_mlt = sales_mlt.rename(columns={'variable':'d', 'value':'sales'})\n",
    "\n",
    "\n",
    "\n",
    "calendar = pd.read_csv(DATA_DIR + 'calendar.csv',\n",
    "                       dtype={'wm_yr_wk': np.int32, 'wday': np.int32, \n",
    "                              'month': np.int32, 'year': np.int32, \n",
    "                              'snap_CA': np.int32, 'snap_TX': np.int32,\n",
    "                              'snap_WI': np.int32})\n",
    "\n",
    "# subsetting calender by traning period\n",
    "calendar = calendar.loc[calendar.d.apply(lambda x: int(x[2:])) \\\n",
    "                        >= int(sales_mlt.d[0][2:]), :]\n",
    "\n",
    "prices = pd.read_csv(DATA_DIR + 'sell_prices.csv',\n",
    "                          dtype={'wm_yr_wk': np.int32, \n",
    "                                 'sell_price': np.float32})\n",
    "prices = prices.loc[prices.wm_yr_wk >= calendar.wm_yr_wk.values[0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calendar = pd.read_csv(\"../data/calendar.csv\")\n",
    "df_prices = pd.read_csv(\"../data/sell_prices.csv\")\n",
    "df_sample_submission = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "df_sample_submission[\"order\"] = range(df_sample_submission.shape[0])\n",
    "\n",
    "df_train = df_train_full.iloc[:, :-28]\n",
    "df_valid = df_train_full.iloc[:, -28:]\n",
    "\n",
    "evaluator = WRMSSEEvaluator(df_train, df_valid, df_calendar, df_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_f = \"/home/timetraveller/Desktop/tch.csv\"\n",
    "preds_valid = pd.read_csv(sub_f)\n",
    "nums = preds_valid.iloc[:30490, 1:]\n",
    "print((nums < 1).mean().values)\n",
    "print((nums < 1).mean().values.mean())\n",
    "nums = evaluator.valid_df[evaluator.valid_target_columns]\n",
    "print(\"\\n\", (nums < 1).mean().values)\n",
    "print((nums < 1).mean().values.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_valid = pd.read_csv(sub_f)\n",
    "preds_valid = preds_valid[preds_valid.id.str.contains(\"validation\")]\n",
    "preds_valid = preds_valid.merge(df_sample_submission[[\"id\", \"order\"]], on = \"id\").sort_values(\"order\").drop([\"id\", \"order\"], axis = 1).reset_index(drop = True)\n",
    "preds_valid.rename(columns = {\n",
    "    \"F1\": \"d_1914\", \"F2\": \"d_1915\", \"F3\": \"d_1916\", \"F4\": \"d_1917\", \"F5\": \"d_1918\", \"F6\": \"d_1919\", \"F7\": \"d_1920\",\n",
    "    \"F8\": \"d_1921\", \"F9\": \"d_1922\", \"F10\": \"d_1923\", \"F11\": \"d_1924\", \"F12\": \"d_1925\", \"F13\": \"d_1926\", \"F14\": \"d_1927\",\n",
    "    \"F15\": \"d_1928\", \"F16\": \"d_1929\", \"F17\": \"d_1930\", \"F18\": \"d_1931\", \"F19\": \"d_1932\", \"F20\": \"d_1933\", \"F21\": \"d_1934\",\n",
    "    \"F22\": \"d_1935\", \"F23\": \"d_1936\", \"F24\": \"d_1937\", \"F25\": \"d_1938\", \"F26\": \"d_1939\", \"F27\": \"d_1940\", \"F28\": \"d_1941\"\n",
    "}, inplace = True)\n",
    "score = evaluator.score(preds_valid)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_viz_df(df,lv):\n",
    "    \n",
    "    df = df.T.reset_index()\n",
    "    if lv in [6,7,8,9,11,12]:\n",
    "        df.columns = [i[0] + '_' + i[1] if i != ('index','') \\\n",
    "                      else i[0] for i in df.columns]\n",
    "    df = df.merge(calendar.loc[:, ['d','date']], how='left', \n",
    "                  left_on='index', right_on='d')\n",
    "    df['date'] = pd.to_datetime(df.date)\n",
    "    df = df.set_index('date')\n",
    "    df = df.drop(['index', 'd'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_dashboard(evaluator):\n",
    "    \n",
    "    wrmsses = [np.mean(evaluator.all_scores)] + evaluator.all_scores\n",
    "    labels = ['Overall'] + [f'Level {i}' for i in range(1, 13)]\n",
    "\n",
    "    ## WRMSSE by Level\n",
    "    plt.figure(figsize=(12,5))\n",
    "    ax = sns.barplot(x=labels, y=wrmsses)\n",
    "    ax.set(xlabel='', ylabel='WRMSSE')\n",
    "    plt.title('WRMSSE by Level', fontsize=20, fontweight='bold')\n",
    "    for index, val in enumerate(wrmsses):\n",
    "        ax.text(index*1, val+.01, round(val,4), color='black', \n",
    "                ha=\"center\")\n",
    "        \n",
    "    # configuration array for the charts\n",
    "    n_rows = [1, 1, 4, 1, 3, 3, 3, 3, 3, 3, 3, 3]\n",
    "    n_cols = [1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
    "    width = [7, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
    "    height = [4, 3, 12, 3, 9, 9, 9, 9, 9, 9, 9, 9]\n",
    "    \n",
    "    for i in range(1,13):\n",
    "        \n",
    "        scores = getattr(evaluator, f'lv{i}_scores')\n",
    "        weights = getattr(evaluator, f'lv{i}_weight')\n",
    "        \n",
    "        if i > 1 and i < 9:\n",
    "            if i < 7:\n",
    "                fig, axs = plt.subplots(1, 2, figsize=(12, 3))\n",
    "            else:\n",
    "                fig, axs = plt.subplots(2, 1, figsize=(12, 8))\n",
    "                \n",
    "            ## RMSSE plot\n",
    "            scores.plot.bar(width=.8, ax=axs[0], color='g')\n",
    "            axs[0].set_title(f\"RMSSE\", size=14)\n",
    "            axs[0].set(xlabel='', ylabel='RMSSE')\n",
    "            if i >= 4:\n",
    "                axs[0].tick_params(labelsize=8)\n",
    "            for index, val in enumerate(scores):\n",
    "                axs[0].text(index*1, val+.01, round(val,4), color='black', \n",
    "                            ha=\"center\", fontsize=10 if i == 2 else 8)\n",
    "            \n",
    "            ## Weight plot\n",
    "            weights.plot.bar(width=.8, ax=axs[1])\n",
    "            axs[1].set_title(f\"Weight\", size=14)\n",
    "            axs[1].set(xlabel='', ylabel='Weight')\n",
    "            if i >= 4:\n",
    "                axs[1].tick_params(labelsize=8)\n",
    "            for index, val in enumerate(weights):\n",
    "                axs[1].text(index*1, val+.01, round(val,2), color='black', \n",
    "                            ha=\"center\", fontsize=10 if i == 2 else 8)\n",
    "                    \n",
    "            fig.suptitle(f'Level {i}: {evaluator.group_ids[i-1]}', size=24 ,\n",
    "                         y=1.1, fontweight='bold')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        trn = create_viz_df(getattr(evaluator, f'lv{i}_train_df')\\\n",
    "                            .iloc[:, -28*3:], i)\n",
    "        val = create_viz_df(getattr(evaluator, f'lv{i}_valid_df'), i)\n",
    "        pred = create_viz_df(getattr(evaluator, f'lv{i}_valid_preds'), i)\n",
    "\n",
    "        n_cate = trn.shape[1] if i < 7 else 9\n",
    "\n",
    "        fig, axs = plt.subplots(n_rows[i-1], n_cols[i-1], \n",
    "                                figsize=(width[i-1],height[i-1]))\n",
    "        if i > 1:\n",
    "            axs = axs.flatten()\n",
    "\n",
    "        ## Time series plot\n",
    "        for k in range(0, n_cate):\n",
    "\n",
    "            ax = axs[k] if i > 1 else axs\n",
    "\n",
    "            trn.iloc[:, k].plot(ax=ax, label='train')\n",
    "            val.iloc[:, k].plot(ax=ax, label='valid')\n",
    "            pred.iloc[:, k].plot(ax=ax, label='pred')\n",
    "            ax.set_title(f\"{trn.columns[k]}  RMSSE:{scores[k]:.4f}\", size=14)\n",
    "            ax.set(xlabel='', ylabel='sales')\n",
    "            ax.tick_params(labelsize=8)\n",
    "            ax.legend(loc='upper left', prop={'size': 10})\n",
    "\n",
    "        if i == 1 or i >= 9:\n",
    "            fig.suptitle(f'Level {i}: {evaluator.group_ids[i-1]}', size=24 , \n",
    "                         y=1.1, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_dashboard(evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
